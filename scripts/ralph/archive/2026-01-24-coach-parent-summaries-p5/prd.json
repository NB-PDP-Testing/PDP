{
  "project": "Phase 5.3 (Cost Optimization)",
  "branchName": "ralph/coach-parent-summaries-p5-phase3",
  "description": "Reduce AI costs by 90% through Anthropic prompt caching and comprehensive usage tracking. Add analytics dashboard for monitoring costs by org/coach/player.",
  "contextAndDependencies": {
    "previousPhases": {
      "phase1": "US-001 to US-006 - Preview mode, confidence visualization, trust slider UI",
      "phase2": "US-007 to US-011 - Auto-approval system with trust levels"
    },
    "requiredTables": [
      "coachParentSummaries - Contains summaries being generated",
      "coachTrustLevels - Trust level data for coaches",
      "aiUsageLog (NEW) - Will track token usage and costs"
    ],
    "requiredActions": [
      "generateParentSummary at packages/backend/convex/actions/generateParentSummary.ts - Makes Anthropic API calls"
    ],
    "keyFiles": [
      "Schema: packages/backend/convex/schema.ts",
      "Action: packages/backend/convex/actions/generateParentSummary.ts",
      "Models: packages/backend/convex/models/aiUsageLog.ts (to be created)"
    ]
  },
  "philosophyAndGoals": {
    "corePhilosophy": "AI should be cost-effective and transparent. Cache what doesn't change, track everything, make costs visible to org admins.",
    "industryPatterns": [
      "Anthropic Prompt Caching: 90% cost reduction on static content",
      "Vercel Analytics: Track usage by org/team for chargeback",
      "Stripe Billing: Show breakdown of what drives costs",
      "DataDog: Real-time cost monitoring and alerting"
    ],
    "successMetrics": {
      "costReduction": "90% reduction in AI costs for parent summaries via caching",
      "visibility": "100% of AI calls logged with token counts and costs",
      "analytics": "Org admins can see AI spend by coach, player, operation",
      "cacheHitRate": ">80% cache hit rate on repeat summaries within 5 minutes"
    }
  },
  "userStories": [
    {
      "id": "US-012",
      "title": "Add prompt caching to generateParentSummary action",
      "description": "As a platform, I reduce AI costs by 90% through Anthropic prompt caching.",
      "acceptanceCriteria": [
        "Edit packages/backend/convex/actions/generateParentSummary.ts",
        "Add anthropic-beta header: 'anthropic-beta': 'prompt-caching-2024-07-31'",
        "Structure messages array to cache system prompt and player/sport context",
        "Only insight content varies (no cache on that)",
        "Extract cache statistics from API response: usage.cache_creation_input_tokens, usage.cache_read_input_tokens",
        "Update cost calculation: (input_tokens - cached_tokens) * 0.000005 + cached_tokens * 0.0000005 + output_tokens * 0.000015",
        "Return cache stats in action response for logging",
        "Typecheck passes: npm run check-types"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Anthropic prompt caching caches static content for 5 minutes. System prompts and player context are perfect candidates. Only the insight content changes per summary. Claude Haiku pricing: Regular input $5/M, Cached $0.50/M (90% discount), Output $15/M. Cache-control header required."
    },
    {
      "id": "US-013",
      "title": "Add aiUsageLog table to schema",
      "description": "As a platform, I track every AI call for cost visibility and analytics.",
      "acceptanceCriteria": [
        "Edit packages/backend/convex/schema.ts",
        "Add new table aiUsageLog with fields:",
        "  timestamp: v.number() - Date.now() when call made",
        "  organizationId: v.id('organization') - Which org incurred the cost",
        "  coachId: v.string() - Which coach triggered the call",
        "  playerId: v.optional(v.id('orgPlayerEnrollments')) - Which player (if applicable)",
        "  operation: v.string() - Type of operation: 'parent_summary', 'voice_note_transcription', etc.",
        "  model: v.string() - Model used: 'claude-3-haiku-20240307'",
        "  inputTokens: v.number() - Total input tokens",
        "  cachedTokens: v.number() - Cached input tokens (0 if no cache)",
        "  outputTokens: v.number() - Output tokens generated",
        "  cost: v.number() - Cost in dollars (e.g., 0.00015)",
        "  cacheHitRate: v.number() - Percentage cached (cachedTokens / inputTokens)",
        "Add indexes: by_organizationId, by_coachId, by_timestamp, by_operation",
        "Run: npx -w packages/backend convex codegen",
        "Typecheck passes: npm run check-types"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Single source of truth for all AI usage. Enables cost analytics, chargeback to orgs, identifying heavy users, tracking cache effectiveness. Store cost as dollars with full precision (don't round)."
    },
    {
      "id": "US-014",
      "title": "Log AI usage in generateParentSummary action",
      "description": "As a platform, every AI call is logged with token counts and costs.",
      "acceptanceCriteria": [
        "Create packages/backend/convex/models/aiUsageLog.ts",
        "Add mutation logUsage with args: timestamp, organizationId, coachId, playerId, operation, model, inputTokens, cachedTokens, outputTokens, cost, cacheHitRate",
        "Edit packages/backend/convex/actions/generateParentSummary.ts",
        "After successful API call, extract token counts from response.usage",
        "Calculate cost: (inputTokens - cachedTokens) * 0.000005 + cachedTokens * 0.0000005 + outputTokens * 0.000015",
        "Calculate cache hit rate: cachedTokens / inputTokens (0-1 range)",
        "Call ctx.runMutation(internal.models.aiUsageLog.logUsage, { ... }) with all fields",
        "Include error handling: if logging fails, log to console but don't fail the summary creation",
        "Typecheck passes: npm run check-types"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Actions can't access ctx.db - must use ctx.runMutation. Get organizationId, coachId, playerId from voice note context. Model is hardcoded 'claude-3-haiku-20240307'. Operation is 'parent_summary'. Logging should never break summary creation."
    },
    {
      "id": "US-015",
      "title": "Create AI usage analytics dashboard query",
      "description": "As an org admin, I see AI usage and costs for my organization.",
      "acceptanceCriteria": [
        "In packages/backend/convex/models/aiUsageLog.ts, add query getOrgUsage",
        "Args: organizationId, startDate (optional), endDate (optional)",
        "Use by_organizationId index with filter for date range",
        "Calculate aggregates:",
        "  totalCost: sum of all cost fields",
        "  totalInputTokens: sum of inputTokens",
        "  totalCachedTokens: sum of cachedTokens",
        "  totalOutputTokens: sum of outputTokens",
        "  averageCacheHitRate: average of cacheHitRate",
        "  callCount: number of log entries",
        "Group by operation type with breakdown",
        "Top 5 coaches by usage",
        "Top 5 players by usage",
        "Add returns validator with full analytics structure",
        "Typecheck passes: npm run check-types"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Query pattern: use index, filter in JS for date range (Convex doesn't support range queries on non-indexed fields). Consider pagination if result set is large (>1000 entries). Return empty structure if no data. This enables cost visibility and chargeback."
    }
  ]
}
