# UAT Test: US-014 - Log AI usage in generateParentSummary action

> Auto-generated: 2026-01-24 23:52
> Status: ‚è≥ Pending Execution

## Story
As a platform, every AI call is logged with token counts and costs.

## Acceptance Criteria Checklist

- [ ] Create packages/backend/convex/models/aiUsageLog.ts
- [ ] Add mutation logUsage with args: timestamp, organizationId, coachId, playerId, operation, model, inputTokens, cachedTokens, outputTokens, cost, cacheHitRate
- [ ] Edit packages/backend/convex/actions/generateParentSummary.ts
- [ ] After successful API call, extract token counts from response.usage
- [ ] Calculate cost: (inputTokens - cachedTokens) * 0.000005 + cachedTokens * 0.0000005 + outputTokens * 0.000015
- [ ] Calculate cache hit rate: cachedTokens / inputTokens (0-1 range)
- [ ] Call ctx.runMutation(internal.models.aiUsageLog.logUsage, { ... }) with all fields
- [ ] Include error handling: if logging fails, log to console but don't fail the summary creation
- [ ] Typecheck passes: npm run check-types

## Test Scenarios

### Happy Path
1. Navigate to the feature
2. Perform the primary action described in the story
3. Verify all acceptance criteria are met
4. **Expected:** Feature works as described

### Edge Cases
1. Test with empty/null values
2. Test with boundary values
3. Test rapid repeated actions
4. **Expected:** Graceful handling, no errors

### Error Handling
1. Test with invalid inputs
2. Test without proper permissions
3. Test with network issues (if applicable)
4. **Expected:** Clear error messages, no crashes

## Visual Verification
- [ ] UI matches design expectations
- [ ] Responsive on mobile (if applicable)
- [ ] Loading states are appropriate
- [ ] Error states are user-friendly

## Notes
_Add testing observations here_

---
*Generated by Test Runner Agent*
