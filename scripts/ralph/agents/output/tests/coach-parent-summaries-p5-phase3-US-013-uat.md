# UAT Test: US-013 - Add aiUsageLog table to schema

> Auto-generated: 2026-01-24 23:51
> Status: ‚è≥ Pending Execution

## Story
As a platform, I track every AI call for cost visibility and analytics.

## Acceptance Criteria Checklist

- [ ] Edit packages/backend/convex/schema.ts
- [ ] Add new table aiUsageLog with fields:
- [ ] timestamp: v.number() - Date.now() when call made
- [ ] organizationId: v.id('organization') - Which org incurred the cost
- [ ] coachId: v.string() - Which coach triggered the call
- [ ] playerId: v.optional(v.id('orgPlayerEnrollments')) - Which player (if applicable)
- [ ] operation: v.string() - Type of operation: 'parent_summary', 'voice_note_transcription', etc.
- [ ] model: v.string() - Model used: 'claude-3-haiku-20240307'
- [ ] inputTokens: v.number() - Total input tokens
- [ ] cachedTokens: v.number() - Cached input tokens (0 if no cache)
- [ ] outputTokens: v.number() - Output tokens generated
- [ ] cost: v.number() - Cost in dollars (e.g., 0.00015)
- [ ] cacheHitRate: v.number() - Percentage cached (cachedTokens / inputTokens)
- [ ] Add indexes: by_organizationId, by_coachId, by_timestamp, by_operation
- [ ] Run: npx -w packages/backend convex codegen
- [ ] Typecheck passes: npm run check-types

## Test Scenarios

### Happy Path
1. Navigate to the feature
2. Perform the primary action described in the story
3. Verify all acceptance criteria are met
4. **Expected:** Feature works as described

### Edge Cases
1. Test with empty/null values
2. Test with boundary values
3. Test rapid repeated actions
4. **Expected:** Graceful handling, no errors

### Error Handling
1. Test with invalid inputs
2. Test without proper permissions
3. Test with network issues (if applicable)
4. **Expected:** Clear error messages, no crashes

## Visual Verification
- [ ] UI matches design expectations
- [ ] Responsive on mobile (if applicable)
- [ ] Loading states are appropriate
- [ ] Error states are user-friendly

## Notes
_Add testing observations here_

---
*Generated by Test Runner Agent*
