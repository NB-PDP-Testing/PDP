# Ralph Progress Log
Started: Mon 16 Feb 2026 19:11:28 GMT
---

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# CODEBASE PATTERNS (MANDATORY - Read this section FIRST!)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

## Voice Notes v2 Pipeline Architecture

**Purpose:** Monitoring harness for voice note processing pipeline
**Phases:** M1 (Backend Instrumentation) → M2 (Metrics & Aggregation) → M3 (Retry Operations) → M4 (Alerts) → M5-M9 (Frontend)

**Pipeline Flow:**
1. Ingestion: voiceNoteArtifacts created (v2 system, replaces v1 voiceNotes)
2. Transcription: audio → text (Deepgram API)
3. Claims Extraction: text → player claims (GPT-4o)
4. Entity Resolution: link claims to players (auto-resolve or manual disambiguation)
5. Draft Generation: claims → insight drafts for parents

**Event Logging Pattern:**
- All pipeline stages emit events to voicePipelineEvents table
- Events are fire-and-forget (ctx.scheduler.runAfter, non-blocking)
- Atomic counter increment on each event (voicePipelineCounters)
- Time-window partitioning: 'YYYY-MM-DD-HH' format

## M1 Critical Patterns (Backend Instrumentation)

**Fire-and-Forget Event Logging:**
```typescript
// In mutations:
ctx.scheduler.runAfter(0, internal.models.voicePipelineEvents.logEvent, { ... });

// In actions:
await ctx.runMutation(internal.models.voicePipelineEvents.logEvent, { ... });
```

**Atomic Counter Increment (M1 Lesson):**
- logEvent mutation does TWO things atomically:
  1. Insert event into voicePipelineEvents
  2. Increment/reset voicePipelineCounters in SAME transaction

**Auth Pattern:**
- All monitoring queries verify isPlatformStaff before proceeding

## M2 Critical Patterns (Metrics & Aggregation)

**UTC Time Handling (MANDATORY):**
```typescript
const year = date.getUTCFullYear();
const month = String(date.getUTCMonth() + 1).padStart(2, "0");
const day = String(date.getUTCDate()).padStart(2, "0");
const hour = String(date.getUTCHours()).padStart(2, "0");
```
NEVER use local time methods (getHours, getMonth, getDate).

**Safe Division (MANDATORY):**
```typescript
function safeDivide(n: number, d: number): number {
  return d > 0 ? n / d : 0;
}
```
Use EVERYWHERE rates/averages are calculated.

**N+1 Prevention (MANDATORY):**
```typescript
// Batch fetch + Map pattern
const uniqueIds = [...new Set(items.map(i => i.id))];
const data = await Promise.all(uniqueIds.map(id => ctx.db.get(id)));
const dataMap = new Map();
for (const d of data) { if (d) dataMap.set(d._id, d); }
const enriched = items.map(i => ({ ...i, data: dataMap.get(i.id) }));
```

**Better Auth Adapter Queries:**
```typescript
// CORRECT:
await ctx.runQuery(components.betterAuth.adapter.findOne, {
  model: "organization",
  where: [{ field: "_id", value: orgId }]  // Array of objects!
});

// WRONG: where: { _id: orgId } (not an object!)
```

**Cron Timing:**
- Hourly at :30 (not :00) - ensures full hour complete
- Daily at 1:30 AM UTC (not 12:00 AM) - ensures 24 hourly snapshots exist
- Cron args with Date.now() freeze at deployment → use wrapper functions

**Platform-Wide Data:**
- Platform-wide: `organizationId: undefined` (omit field)
- Org-specific: `organizationId: orgId` (present)
- NEVER use null

## M3 Critical Patterns (Retry Operations - CURRENT PHASE)

**Platform Staff Authorization (ALL retry mutations):**
```typescript
const user = await authComponent.safeGetAuthUser(ctx);
if (!user) throw new Error("Not authenticated");
const dbUser = await ctx.runQuery(components.betterAuth.adapter.findOne, {
  model: "user",
  where: [{ field: "_id", value: user._id }]
});
if (!dbUser?.isPlatformStaff) throw new Error("Not authorized");
```

**Retry Event Logging (MANDATORY BEFORE scheduling):**
```typescript
// 1. Count previous retries
const prevRetries = await ctx.db.query("voicePipelineEvents")
  .withIndex("by_artifactId", q => q.eq("artifactId", artifactId))
  .filter(q => q.eq(q.field("eventType"), "retry_initiated"))
  .collect();
const retryAttempt = prevRetries.length + 1;

// 2. Log retry_initiated BEFORE scheduling action
await ctx.scheduler.runAfter(0, internal.models.voicePipelineEvents.logEvent, {
  eventType: "retry_initiated",
  artifactId,
  metadata: { retryAttempt, retryType: "transcription" }
});

// 3. Reset artifact status
await ctx.db.patch(artifactId, { status: "transcribing" });

// 4. Schedule action (fire-and-forget)
const artifact = await ctx.db.get(artifactId);
await ctx.scheduler.runAfter(0, internal.actions.voiceNotes.transcribeAudio, {
  noteId: artifact.voiceNoteId  // CRITICAL: noteId, NOT artifactId!
});
```

**transcribeAudio Action Signature (M3 Gotcha):**
- Takes `noteId: v.id("voiceNotes")` (v1 system)
- NOT `artifactId: v.id("voiceNoteArtifacts")` (v2 system)
- Must fetch `artifact.voiceNoteId` before scheduling

**Full Pipeline Retry (DESTRUCTIVE - M3):**
```typescript
try {
  // Delete ALL derived data in order
  const transcript = await ctx.db.query("voiceNoteTranscripts")
    .withIndex("by_artifactId", q => q.eq("artifactId", artifactId))
    .first();
  if (transcript) await ctx.db.delete(transcript._id);

  const claims = await ctx.db.query("voiceNoteClaims")
    .withIndex("by_artifactId", q => q.eq("artifactId", artifactId))
    .collect();
  for (const claim of claims) await ctx.db.delete(claim._id);

  const resolutions = await ctx.db.query("voiceNoteEntityResolutions")
    .withIndex("by_artifactId", q => q.eq("artifactId", artifactId))
    .collect();
  for (const res of resolutions) await ctx.db.delete(res._id);

  const drafts = await ctx.db.query("insightDrafts")
    .withIndex("by_artifactId", q => q.eq("artifactId", artifactId))
    .collect();
  for (const draft of drafts) await ctx.db.delete(draft._id);

  // Only if ALL deletes succeed: reset status and schedule
  await ctx.db.patch(artifactId, { status: "received" });
  const artifact = await ctx.db.get(artifactId);
  await ctx.scheduler.runAfter(0, internal.actions.voiceNotes.transcribeAudio, {
    noteId: artifact.voiceNoteId
  });
} catch (error) {
  console.error("Full retry cleanup failed:", error);
  return { success: false, message: "Cleanup failed - aborted" };
}
```

## Convex Backend Patterns (ALWAYS FOLLOW)

**Index Usage (MANDATORY):**
```typescript
// ✅ GOOD:
await ctx.db.query("table").withIndex("by_field", q => q.eq("field", value)).collect();

// ❌ BAD:
await ctx.db.query("table").filter(q => q.eq(q.field("field"), value)).collect();
```

**Fire-and-Forget Scheduling:**
```typescript
// ✅ GOOD (non-blocking):
await ctx.scheduler.runAfter(0, internal.models.someFunction, { ... });

// ❌ BAD (blocks mutation):
await ctx.runAction(internal.actions.someAction, { ... });
```

## Code Quality Patterns (MANDATORY)

**Atomic Imports (CRITICAL):**
- Add import AND first usage in SAME edit
- Linter removes "unused" imports between edits
- NEVER add import in one edit, usage in next edit

**Linter Strictness:**
- NO `!` non-null assertions
- NO `?.x!` optional chain + non-null
- NO `++` operator (use `+= 1`)
- ALWAYS use block statements: `if (x) { return; }` NOT `if (x) return;`

**Error Handling in Crons:**
- Log errors but return successfully (no throw)
- Throwing causes infinite cron retries

---

## 2026-02-16 20:45 - US-VNM-004 & US-VNM-005 - M2 Metrics Aggregation Complete
**Iteration**: 1
**Commit**: b19b0d769216cc9a4233ece61dc8e3ab9d9c6be3
**Session**: f9990f07-56ce-47fb-8595-7cc640715716
**Status**: Complete

### What was implemented
- Created voicePipelineMetrics.ts with 8 core functions + 2 wrappers
- Implemented getRealTimeMetrics: O(1) counter reads (< 50ms target)
- Implemented getHistoricalMetrics: Query snapshots by time range
- Implemented getStageBreakdown: Per-stage latency and failure rates
- Implemented getOrgBreakdown: Per-org metrics with batch fetch pattern
- Implemented aggregateHourlyMetrics: Events → hourly snapshots
- Implemented aggregateDailyMetrics: Hourly → daily snapshots
- Implemented cleanupOldSnapshots: 7d hourly, 90d daily retention
- Implemented cleanupOldEvents: 48h event retention
- Added 4 cron jobs to crons.ts with correct timing
- Created wrapper functions to calculate timestamps at runtime

### Files changed
- packages/backend/convex/models/voicePipelineMetrics.ts (+1356 lines, new file)
- packages/backend/convex/crons.ts (+36, -1)

### Quality checks
- ✅ Type check: passed (codegen succeeded)
- ✅ Linting: passed (biome check clean)
- ✅ Pre-commit hooks: passed
- ✅ Better Auth adapter: Used ctx.runQuery with correct where array syntax
- ✅ UTC time handling: All time calculations use getUTCHours(), getUTCMonth(), getUTCDate()
- ✅ Safe division: All rate calculations check denominator > 0
- ✅ N+1 prevention: Batch fetch org names using Map pattern
- ✅ No event scanning: Real-time metrics only read counters
- ✅ Platform staff auth: All queries verify isPlatformStaff

### **Learnings for future iterations** ⚠️ CRITICAL

**Patterns discovered:**
- Better Auth adapter queries need `where` as array: `[{ field: "_id", value: id }]`
- ctx.runQuery must be used for adapter methods (findOne, findMany, etc.)
- Cron args with Date.now() evaluate once at deployment, not per-execution
- Wrapper functions needed to calculate timestamps at runtime
- Ternary operator for snapshots query avoided `let snapshots` implicit any
- Atomic imports: Added import + first usage in same edit (linter removed unused)

**Gotchas encountered:**
- Linter removed unused import when added separately from usage
- Non-null assertions (!), optional chain + non-null (?.x!), and ++ operator not allowed
- Must use block statements for single-line if: `if (x) { return; }`
- Safe division pattern: `denominator > 0 ? n / d : 0` prevents NaN/Infinity

**Dependencies found:**
- internal.models.voicePipelineMetrics.* exported functions visible in crons
- components.betterAuth.adapter.findOne for org name batch fetch
- ctx.runMutation for calling internal functions from wrapper functions

**What to do next:**
- [x] US-VNM-004: Complete
- [x] US-VNM-005: Complete
- [ ] Manual testing via Convex dashboard (as documented in PRD)
- [ ] Verify crons visible in Convex dashboard after deployment
- [ ] Manually trigger crons to test execution
- [ ] Verify snapshots created correctly

**Mistakes made:**
- Initially used adapter.findOne directly (not callable) - fixed to ctx.runQuery
- Initially passed Date.now() in cron args (would freeze at deployment) - created wrappers
- Initially forgot to add block statement for single-line if - linter caught this

**M2 PRD Compliance:**
✅ All 8 functions from PHASE_M2.json implemented
✅ All 4 crons from PHASE_M2.json added
✅ Hourly cron at :30 (not :00) as specified
✅ Daily cron at 1:30 AM (not 12:00 AM) as specified
✅ Batch fetch pattern used in getOrgBreakdown
✅ UTC time handling throughout
✅ Safe division for all rate calculations
✅ Error handling: functions log errors but return successfully

---

## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
## PHASE M3 - Retry Operations (CURRENT PHASE)
## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**Phase Start:** 2026-02-16 21:00
**Dependencies:** M1 (complete), M2 (complete)
**Duration:** 2-3 days (estimated)
**Status:** Ready to start

### M3 Goals

1. Enable manual retry for transcription failures
2. Enable manual retry for claims extraction failures
3. Enable manual retry for entity resolution failures
4. Enable full pipeline retry from beginning (DESTRUCTIVE)
5. Audit log all retry operations (retry_initiated/retry_succeeded/retry_failed)
6. Track retry history per artifact

### M3 User Stories

**US-VNM-006: Build Retry Operations Backend**
- Create `packages/backend/convex/models/voicePipelineRetry.ts`
- Implement 5 functions:
  1. `retryTranscription` mutation
  2. `retryClaimsExtraction` mutation
  3. `retryEntityResolution` mutation
  4. `retryFullPipeline` mutation (DESTRUCTIVE)
  5. `getRetryHistory` query

### M3 Critical Implementation Details (READ CAREFULLY!)

#### Function Signatures (EXACT - from PHASE_M3.json)

**1. retryTranscription:**
```typescript
export const retryTranscription = mutation({
  args: { artifactId: v.id("voiceNoteArtifacts") },
  returns: v.object({ success: v.boolean(), message: v.string() }),
  handler: async (ctx, args) => {
    // 1. Verify platform staff auth
    // 2. Fetch artifact, verify transcription failure
    // 3. Count previous retries (query voicePipelineEvents for retry_initiated events)
    // 4. Log retry_initiated with metadata: { retryAttempt: count + 1 }
    // 5. Reset artifact status to 'transcribing'
    // 6. CRITICAL: Get artifact.voiceNoteId (transcribeAudio takes noteId, NOT artifactId!)
    // 7. Schedule: ctx.scheduler.runAfter(0, internal.actions.voiceNotes.transcribeAudio, { noteId: artifact.voiceNoteId })
    // 8. Return { success: true, message: 'Transcription retry initiated' }
  }
});
```

**2. retryClaimsExtraction:**
```typescript
export const retryClaimsExtraction = mutation({
  args: { artifactId: v.id("voiceNoteArtifacts") },
  returns: v.object({ success: v.boolean(), message: v.string() }),
  handler: async (ctx, args) => {
    // Similar to retryTranscription but:
    // - Verify claims extraction failed
    // - Reset status to 'transcribed' (ready for claims)
    // - Schedule: internal.actions.claimsExtraction.extractClaims
  }
});
```

**3. retryEntityResolution:**
```typescript
export const retryEntityResolution = mutation({
  args: { artifactId: v.id("voiceNoteArtifacts") },
  returns: v.object({ success: v.boolean(), message: v.string() }),
  handler: async (ctx, args) => {
    // 1. Verify platform staff auth
    // 2. Fetch artifact, verify resolution failed or needs manual review
    // 3. Log retry_initiated
    // 4. DELETE existing voiceNoteEntityResolutions for this artifact (clean slate)
    // 5. Schedule: internal.actions.entityResolution.resolveEntities
    // 6. Return success
  }
});
```

**4. retryFullPipeline (DESTRUCTIVE):**
```typescript
export const retryFullPipeline = mutation({
  args: { artifactId: v.id("voiceNoteArtifacts") },
  returns: v.object({ success: v.boolean(), message: v.string() }),
  handler: async (ctx, args) => {
    // 1. Verify platform staff auth
    // 2. Fetch artifact
    // 3. Log retry_initiated with metadata: { retryType: 'full_pipeline' }
    // 4. CRITICAL: Delete ALL derived data in try/catch (abort if any fail):
    //    a. Delete voiceNoteTranscripts (by_artifactId index)
    //    b. Delete voiceNoteClaims (by_artifactId index)
    //    c. Delete voiceNoteEntityResolutions (by_artifactId index)
    //    d. Delete insightDrafts (by_artifactId index)
    // 5. Only if ALL deletes succeed: reset artifact status to 'received'
    // 6. Get artifact.voiceNoteId
    // 7. Schedule: ctx.scheduler.runAfter(0, internal.actions.voiceNotes.transcribeAudio, { noteId })
    // 8. Return success
    try {
      // Delete sequence here
    } catch (error) {
      console.error("Full retry cleanup failed:", error);
      return { success: false, message: "Cleanup failed - aborted" };
    }
  }
});
```

**5. getRetryHistory:**
```typescript
export const getRetryHistory = query({
  args: { artifactId: v.id("voiceNoteArtifacts") },
  returns: v.array(v.object({
    timestamp: v.number(),
    eventType: v.string(),
    retryAttempt: v.optional(v.number()),
    succeeded: v.optional(v.boolean()),
    errorMessage: v.optional(v.string())
  })),
  handler: async (ctx, args) => {
    // 1. Verify platform staff auth
    // 2. Query voicePipelineEvents by_artifactId index
    // 3. Filter eventType in ['retry_initiated', 'retry_succeeded', 'retry_failed']
    // 4. Order by timestamp ascending
    // 5. Map to simplified format
    // 6. Return array
  }
});
```

### M3 Critical Gotchas (MUST AVOID!)

**Gotcha #1: transcribeAudio Action Signature**
- ❌ WRONG: `transcribeAudio({ artifactId })`
- ✅ CORRECT: `transcribeAudio({ noteId: artifact.voiceNoteId })`
- **Explanation:** transcribeAudio is a V1 action that takes `v.id("voiceNotes")` noteId, NOT v2 artifactId
- **Fix:** Always fetch artifact first, then use `artifact.voiceNoteId` for scheduling

**Gotcha #2: Retry Attempt Tracking**
- Must query previous retry_initiated events to count retries
- retryAttempt = previousRetryCount + 1
- Include in metadata of retry_initiated event

**Gotcha #3: Full Pipeline Delete Order**
- MUST wrap in try/catch
- If ANY delete fails, abort entire operation (don't leave partial state)
- Delete order: transcripts → claims → resolutions → drafts
- Only reset status if ALL deletes succeed

**Gotcha #4: Fire-and-Forget Pattern**
- ❌ WRONG: `await ctx.runAction(...)` (blocks mutation)
- ✅ CORRECT: `await ctx.scheduler.runAfter(0, ...)` (fire-and-forget)

**Gotcha #5: Event Logging BEFORE Scheduling**
- ALWAYS log retry_initiated BEFORE scheduling action
- If scheduling fails, can log retry_failed

**Gotcha #6: Status Reset BEFORE Scheduling**
- Reset artifact status BEFORE scheduling action
- retryTranscription → status: 'transcribing'
- retryClaimsExtraction → status: 'transcribed'
- retryEntityResolution → (no status change, just delete resolutions)
- retryFullPipeline → status: 'received'

### M3 Action Scheduling Reference

**Pipeline Actions:**
- Transcription: `internal.actions.voiceNotes.transcribeAudio`
- Claims Extraction: `internal.actions.claimsExtraction.extractClaims`
- Entity Resolution: `internal.actions.entityResolution.resolveEntities`
- Draft Generation: `internal.actions.draftGeneration.generateDrafts`

### M3 Testing Strategy

**Manual Testing via Convex Dashboard:**
1. Create artifact with transcription failure (or manually set status to 'failed')
2. Call retryTranscription mutation → verify:
   - retry_initiated event logged
   - Artifact status reset to 'transcribing'
   - transcribeAudio action scheduled (check logs)
   - If succeeds: retry_succeeded event (logged by pipeline)
3. Test retryClaimsExtraction similarly
4. Test retryEntityResolution
5. Test retryFullPipeline → verify:
   - All derived data deleted (transcripts, claims, resolutions, drafts)
   - Artifact reset to 'received'
   - Pipeline starts fresh
6. Call getRetryHistory → verify shows all retry attempts chronologically

### M3 Success Criteria

- [ ] voicePipelineRetry.ts created with 5 functions
- [ ] All retry mutations verify isPlatformStaff
- [ ] retry_initiated events logged BEFORE action scheduled
- [ ] Artifact status reset correctly before retry
- [ ] Retry attempt tracking works (metadata.retryAttempt increments)
- [ ] Full pipeline retry deletes ALL derived data in try/catch
- [ ] getRetryHistory returns complete retry timeline
- [ ] Codegen passes
- [ ] Type check passes

### M3 Common Pitfalls (from PHASE_M3.json)

❌ Forgetting platform staff authorization check
❌ Not logging retry_initiated event before scheduling
❌ Not resetting artifact status before retry
❌ Not incrementing retryAttempt in event metadata
❌ Not deleting derived data on full pipeline retry (leaves corrupt state)
❌ Using ctx.runAction instead of ctx.scheduler.runAfter (blocks mutation)
❌ Passing artifactId to transcribeAudio (should be noteId)
❌ Not wrapping full pipeline deletes in try/catch (partial cleanup on error)

### M3 Mandatory Patterns (from M1 & M2 Lessons)

1. **Platform Staff Auth (ALL mutations):**
   - Verify isPlatformStaff before ANY operation
   - Use Better Auth adapter with array where clause

2. **Fire-and-Forget Scheduling:**
   - Use `ctx.scheduler.runAfter(0, ...)` for all action scheduling
   - NEVER use `await ctx.runAction(...)` in mutations

3. **Atomic Imports:**
   - Add import + first usage in SAME edit
   - Linter removes unused imports between edits

4. **Error Handling:**
   - Log errors but return successfully (UI-called mutations)
   - Full pipeline retry: return error on partial cleanup failure

5. **Convex Patterns:**
   - Use .withIndex() for all queries (NEVER .filter())
   - Better Auth: ctx.runQuery(adapter.findOne, { where: [{ field, value }] })

### What to do next (M3 Execution Order)

1. [ ] Read PHASE_M3.json detailedAcceptanceCriteria (MANDATORY)
2. [ ] Create voicePipelineRetry.ts file
3. [ ] Implement retryTranscription first
   - Add platform staff auth
   - Count previous retry attempts
   - Log retry_initiated with retryAttempt
   - Reset status to 'transcribing'
   - Get artifact.voiceNoteId (NOT artifactId!)
   - Schedule transcribeAudio with noteId
   - Return success
4. [ ] Test retryTranscription via Convex dashboard
5. [ ] Implement retryClaimsExtraction
6. [ ] Implement retryEntityResolution (delete existing resolutions)
7. [ ] Implement retryFullPipeline (DESTRUCTIVE - wrap deletes in try/catch)
8. [ ] Implement getRetryHistory
9. [ ] Test all retry types end-to-end
10. [ ] Run codegen and type check
11. [ ] Commit with learnings
12. [ ] Update prd.json: US-VNM-006 passes: true

### Files to Create

- `packages/backend/convex/models/voicePipelineRetry.ts`

### Context Files to Read (MANDATORY)

- ✅ M1_LESSONS_LEARNED.md (already read)
- ✅ M2_LESSONS_LEARNED.md (already read)
- ⏳ PHASE_M3.json (READ BEFORE STARTING!)
- ⏳ docs/architecture/voice-flow-monitoring-harness.md (lines 834-843)

---
## 2026-02-16 21:30 - US-VNM-006 - Build Retry Operations Backend
**Iteration**: 2
**Commit**: 27e4a1130516ec5b873afe0e49c0bf41d9b5b7e9
**Session**: 623e0f9f-8e71-4048-b10b-9c2f3b01a7d5
**Status**: Complete

### What was implemented
- Created voicePipelineRetry.ts with all 5 functions (4 retry mutations + 1 history query)
- Implemented retryTranscription mutation with platform staff auth, retry tracking, event logging
- Implemented retryClaimsExtraction mutation
- Implemented retryEntityResolution mutation (deletes existing resolutions before retry)
- Implemented retryFullPipeline mutation (DESTRUCTIVE - deletes all derived data in try/catch)
- Implemented getRetryHistory query with platform staff auth
- All retry mutations log retry_initiated BEFORE scheduling action
- All retry mutations reset artifact status BEFORE scheduling action
- Retry attempt tracking via countPreviousRetries helper
- Fire-and-forget scheduling pattern: ctx.scheduler.runAfter(0, ...)
- transcribeAudio scheduled with noteId (artifact.voiceNoteId), NOT artifactId

### Files changed
- packages/backend/convex/models/voicePipelineRetry.ts (+534, new file)
- packages/backend/convex/_generated/api.d.ts (auto-generated)

### Quality checks
- ✅ Type check: passed (codegen succeeded)
- ✅ Linting: passed (biome check clean)
- ✅ Pre-commit hooks: passed
- ✅ Platform staff auth: All mutations and queries verify isPlatformStaff
- ✅ Fire-and-forget pattern: All action scheduling uses ctx.scheduler.runAfter(0, ...)
- ✅ Retry tracking: countPreviousRetries helper queries previous retry_initiated events
- ✅ Event logging BEFORE scheduling: All retry mutations log event first
- ✅ Status reset BEFORE scheduling: All retry mutations reset status first
- ✅ Full pipeline cleanup: Wrapped in try/catch, returns error on partial failure
- ✅ voiceNoteId handling: Check for undefined, return error if missing

### **Learnings for future iterations** ⚠️ CRITICAL

**Patterns discovered:**
- voiceNoteArtifacts schema has `senderUserId` (NOT coachUserId) and `orgContextCandidates` (NOT organizationId)
- Extract organizationId from orgContextCandidates[0].organizationId if present
- voiceNoteId is optional (v.optional(v.id("voiceNotes"))) - must check for undefined before using
- countPreviousRetries helper reusable across all retry mutations
- verifyPlatformStaff helper reusable across all mutations and queries

**Gotchas encountered:**
- Initial attempt used artifact.organizationId and artifact.coachUserId (don't exist)
- Fixed to use orgContextCandidates[0].organizationId and artifact.senderUserId
- Initial attempt didn't check voiceNoteId for undefined - added guard clause
- TypeScript ctx: any warnings - fixed by importing MutationCtx and QueryCtx types
- Biome formatter required single-line function signature

**Dependencies found:**
- internal.actions.voiceNotes.transcribeAudio (takes noteId, not artifactId)
- internal.actions.claimsExtraction.extractClaims (takes artifactId)
- internal.actions.entityResolution.resolveEntities (takes artifactId)
- internal.models.voicePipelineEvents.logEvent (for retry event logging)
- components.betterAuth.adapter.findOne (for platform staff auth check)

**What to do next:**
- [ ] Manual testing via Convex dashboard (as documented in PHASE_M3.json)
- [ ] Test retryTranscription with failed artifact
- [ ] Test retryClaimsExtraction with claims failure
- [ ] Test retryEntityResolution with resolution failure
- [ ] Test retryFullPipeline (DESTRUCTIVE - verify all derived data deleted)
- [ ] Test getRetryHistory shows complete timeline
- [ ] Verify retry_initiated events logged correctly
- [ ] Verify artifact status resets correctly
- [ ] Verify actions scheduled and execute

**Mistakes made:**
- Initially forgot voiceNoteArtifacts schema structure (orgContextCandidates vs organizationId)
- Initially didn't check voiceNoteId for undefined
- Used `ctx: any` initially - should use MutationCtx/QueryCtx from _generated/server

**M3 PRD Compliance:**
✅ All 5 functions from PHASE_M3.json implemented
✅ Platform staff auth in all mutations and queries
✅ Fire-and-forget scheduling: ctx.scheduler.runAfter(0, ...)
✅ Retry tracking: metadata.retryAttempt increments
✅ Event logging BEFORE scheduling
✅ Status reset BEFORE scheduling
✅ Full pipeline retry deletes ALL derived data in try/catch
✅ transcribeAudio uses noteId (artifact.voiceNoteId), NOT artifactId
✅ getRetryHistory filters retry events chronologically
✅ Codegen passes
✅ Type check passes

**Key Implementation Details:**
1. **Platform Staff Auth Pattern:**
   ```typescript
   async function verifyPlatformStaff(ctx: MutationCtx | QueryCtx): Promise<void> {
     const user = await authComponent.safeGetAuthUser(ctx);
     if (!user) throw new Error("Not authenticated");
     const dbUser = await ctx.runQuery(components.betterAuth.adapter.findOne, {
       model: "user",
       where: [{ field: "_id", value: user._id }],
     });
     if (!dbUser?.isPlatformStaff) throw new Error("Not authorized: platform staff only");
   }
   ```

2. **Retry Attempt Tracking:**
   ```typescript
   async function countPreviousRetries(ctx: MutationCtx, artifactId: string): Promise<number> {
     const prevRetries = await ctx.db
       .query("voicePipelineEvents")
       .withIndex("by_artifactId", (q) => q.eq("artifactId", artifactId))
       .collect();
     const retryEvents = prevRetries.filter(
       (event) => event.eventType === "retry_initiated"
     );
     return retryEvents.length;
   }
   ```

3. **Organization ID Extraction:**
   ```typescript
   const organizationId =
     artifact.orgContextCandidates.length > 0
       ? artifact.orgContextCandidates[0].organizationId
       : undefined;
   ```

4. **voiceNoteId Guard:**
   ```typescript
   if (!artifact.voiceNoteId) {
     return {
       success: false,
       message: "Artifact missing voiceNoteId - cannot retry",
     };
   }
   ```

5. **Full Pipeline Cleanup (DESTRUCTIVE):**
   ```typescript
   try {
     // Delete transcripts, claims, resolutions, drafts
     // ...
   } catch (error) {
     console.error("Full pipeline retry cleanup failed:", error);
     return {
       success: false,
       message: "Cleanup failed - aborted to prevent partial state",
     };
   }
   ```

---


## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
## PHASE M4 - Pipeline Alerts (CURRENT PHASE)
## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**Phase Start:** 2026-02-16 21:35
**Phase Goal:** Automated anomaly detection with health check cron
**PRD:** /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/phases/PHASE_M4.json
**Dependencies:** M1 ✅ | M2 ✅ | M3 ✅

### Phase M4 Overview

**What we're building:**
- Automated health checks (every 5 minutes)
- 6 alert types: HIGH_FAILURE_RATE, HIGH_LATENCY, HIGH_QUEUE_DEPTH, DISAMBIGUATION_BACKLOG, CIRCUIT_BREAKER_OPEN, INACTIVITY
- Alert deduplication (no spam)
- Platform staff alert management

**Files to create:**
- /Users/neil/Documents/GitHub/PDP/packages/backend/convex/models/voicePipelineAlerts.ts (new file)

**Files to modify:**
- /Users/neil/Documents/GitHub/PDP/packages/backend/convex/crons.ts (add cron job)

### US-VNM-007: Build Pipeline Alerts Backend

**Functions to implement:**

1. **checkPipelineHealth** (internalMutation)
   - Query voicePipelineCounters for real-time metrics
   - Query voicePipelineMetricsSnapshots for historical baseline (last 168 hourly snapshots = 7 days)
   - Perform 6 health checks:
     - Failure Rate: `failures / (completed + failures) > 0.10` → PIPELINE_HIGH_FAILURE_RATE (severity: high)
     - Latency Spike: `current latency > 2x 7-day avg` → PIPELINE_HIGH_LATENCY (severity: medium)
     - Queue Depth: `active artifacts > 50` → PIPELINE_HIGH_QUEUE_DEPTH (severity: medium)
     - Disambiguation Backlog: `needs_disambiguation > 100` → PIPELINE_DISAMBIGUATION_BACKLOG (severity: low)
     - Circuit Breaker: `state='open' or 'half_open'` → PIPELINE_CIRCUIT_BREAKER_OPEN (severity: critical)
     - Pipeline Inactivity: `no artifacts received in 60+ min` → PIPELINE_INACTIVITY (severity: low)
   - Deduplicate alerts: check if same alertType exists with acknowledged=false before inserting
   - Insert alerts into platformCostAlerts table
   - Return { alertsCreated: number, checksPerformed: string[] }

2. **getActiveAlerts** (query, platform staff only)
   - Query platformCostAlerts: acknowledged=false AND alertType starts with 'PIPELINE_'
   - Order by severity (critical > high > medium > low), then createdAt desc
   - Return array

3. **acknowledgeAlert** (mutation, platform staff only)
   - Update alert: acknowledged=true, acknowledgedAt=Date.now(), acknowledgedBy=user._id
   - Return { success: true }

4. **getAlertHistory** (query, platform staff only)
   - Query platformCostAlerts: alertType starts with 'PIPELINE_'
   - Apply optional filters (severity, alertType, date range)
   - Order by createdAt desc
   - Use .paginate(paginationOpts)
   - Return paginated result

**Cron job to add:**
- Name: 'check-pipeline-health'
- Schedule: Every 5 minutes (crons.interval('check-pipeline-health', { minutes: 5 }, ...))
- Action: Call internal.models.voicePipelineAlerts.checkPipelineHealth

### M4 Critical Patterns (READ BEFORE IMPLEMENTING!)

**1. Safe Division (MANDATORY for Failure Rate):**
```typescript
// ❌ WRONG: Can cause NaN/Infinity
const failureRate = failures / (completed + failures);

// ✅ CORRECT: Handle divide-by-zero
const total = completed + failures;
const failureRate = total > 0 ? failures / total : 0;
```

**2. Alert Deduplication (MANDATORY):**
```typescript
// Before creating alert, check if same alertType already exists unacknowledged
const existingAlert = await ctx.db
  .query("platformCostAlerts")
  .withIndex("by_acknowledged", (q) => q.eq("acknowledged", false))
  .collect();

const hasDuplicate = existingAlert.some(
  (alert) => alert.alertType === "PIPELINE_HIGH_FAILURE_RATE"
);

if (!hasDuplicate) {
  // Only create alert if no existing unacknowledged alert of same type
  await ctx.db.insert("platformCostAlerts", {
    alertType: "PIPELINE_HIGH_FAILURE_RATE",
    severity: "high",
    message: `Pipeline failure rate is ${failureRate * 100}% (threshold: 10%)`,
    acknowledged: false,
    metadata: { failureRate, threshold: 0.10 },
    createdAt: Date.now(),
  });
}
```

**3. Latency Baseline Calculation (7-day rolling average):**
```typescript
// Query last 168 hourly snapshots (7 days)
const snapshots = await ctx.db
  .query("voicePipelineMetricsSnapshots")
  .withIndex("by_periodType_and_windowEnd", (q) =>
    q.eq("periodType", "hourly")
  )
  .order("desc")
  .take(168);

// Calculate average latency
const total = snapshots.reduce((sum, s) => sum + s.avgEndToEndLatency, 0);
const historicalAvg = snapshots.length > 0 ? total / snapshots.length : 0;

// Check if current latency > 2x historical
const currentLatency = realTimeMetrics.avgEndToEndLatency;
if (currentLatency > historicalAvg * 2) {
  // Create latency alert
}
```

**4. Platform Staff Authorization (ALL queries/mutations):**
```typescript
// Reuse M3 pattern
async function verifyPlatformStaff(ctx: MutationCtx | QueryCtx): Promise<void> {
  const user = await authComponent.safeGetAuthUser(ctx);
  if (!user) throw new Error("Not authenticated");

  const dbUser = await ctx.runQuery(components.betterAuth.adapter.findOne, {
    model: "user",
    where: [{ field: "_id", value: user._id }],
  });

  if (!dbUser?.isPlatformStaff) {
    throw new Error("Not authorized: platform staff only");
  }
}
```

**5. Severity Order (for getActiveAlerts sorting):**
```typescript
const severityOrder = { critical: 0, high: 1, medium: 2, low: 3 };

// Sort by severity first, then createdAt
alerts.sort((a, b) => {
  const severityDiff = severityOrder[a.severity] - severityOrder[b.severity];
  if (severityDiff !== 0) return severityDiff;
  return b.createdAt - a.createdAt;
});
```

**6. Fire-and-Forget Event Emissions (for circuit breaker state changes):**
```typescript
// If circuit breaker state changes, log event
if (currentState !== previousState) {
  await ctx.scheduler.runAfter(0, internal.models.voicePipelineEvents.logEvent, {
    eventType: currentState === "open" ? "circuit_breaker_opened" : "circuit_breaker_closed",
    organizationId: undefined,  // Platform-wide event
    metadata: { state: currentState, recentFailureCount },
  });
}
```

**7. Active Artifacts Query (for Queue Depth check):**
```typescript
// Query artifacts in active statuses
const activeStatuses = ["received", "transcribing", "transcribed", "processing"];

// Count using index
let queueDepth = 0;
for (const status of activeStatuses) {
  const artifacts = await ctx.db
    .query("voiceNoteArtifacts")
    .withIndex("by_status", (q) => q.eq("status", status))
    .collect();
  queueDepth += artifacts.length;
}
```

**8. Cron Interval Pattern (Every 5 Minutes):**
```typescript
// In crons.ts:
crons.interval(
  "check-pipeline-health",
  { minutes: 5 },
  async (ctx) => {
    await ctx.runMutation(internal.models.voicePipelineAlerts.checkPipelineHealth, {});
  }
);
```

### M4 Gotchas to Avoid

1. **❌ Don't spam alerts**
   - Without deduplication, health check creates new alert every 5 minutes
   - ALWAYS check for existing unacknowledged alert before inserting

2. **❌ Don't use .take(168) for latency baseline**
   - WRONG: `.take(168)` not allowed (use .paginate or .collect)
   - CORRECT: Query recent snapshots, collect, then slice to 168

3. **❌ Don't forget safe division**
   - Failure rate calculation: `failures / (completed + failures)`
   - If both completed and failures are 0, this is NaN
   - ALWAYS check denominator > 0

4. **❌ Don't forget platform staff auth**
   - ALL alert queries/mutations MUST verify isPlatformStaff
   - getActiveAlerts, acknowledgeAlert, getAlertHistory

5. **❌ Don't use wrong severity levels**
   - critical: Circuit breaker open (AI service unavailable)
   - high: Failure rate > 10% (significant pipeline degradation)
   - medium: Latency spike or queue depth (performance degradation)
   - low: Disambiguation backlog or inactivity (operational issues)

6. **❌ Don't scan events for real-time metrics**
   - WRONG: Query voicePipelineEvents to count failures
   - CORRECT: Read voicePipelineCounters (O(1) lookup)

7. **❌ Don't use platformCostAlerts if schema is closed**
   - Check schema: if alertType is union of literals, can't extend
   - RECOMMENDATION: Create new voicePipelineAlerts table if time allows
   - FALLBACK: Map 4 severities to 2 (low/medium→warning, high/critical→critical)

### M4 Function Signatures

**checkPipelineHealth:**
```typescript
export const checkPipelineHealth = internalMutation({
  args: {},
  returns: v.object({
    alertsCreated: v.number(),
    checksPerformed: v.array(v.string()),
  }),
  handler: async (ctx, args) => {
    // Implementation
  },
});
```

**getActiveAlerts:**
```typescript
export const getActiveAlerts = query({
  args: {},
  returns: v.array(
    v.object({
      _id: v.id("platformCostAlerts"),
      alertType: v.string(),
      severity: v.string(),
      message: v.string(),
      metadata: v.optional(v.any()),
      createdAt: v.number(),
      acknowledged: v.boolean(),
    })
  ),
  handler: async (ctx, args) => {
    await verifyPlatformStaff(ctx);
    // Implementation
  },
});
```

**acknowledgeAlert:**
```typescript
export const acknowledgeAlert = mutation({
  args: {
    alertId: v.id("platformCostAlerts"),
  },
  returns: v.object({
    success: v.boolean(),
  }),
  handler: async (ctx, args) => {
    await verifyPlatformStaff(ctx);
    // Implementation
  },
});
```

**getAlertHistory:**
```typescript
export const getAlertHistory = query({
  args: {
    filters: v.optional(
      v.object({
        severity: v.optional(v.string()),
        alertType: v.optional(v.string()),
        startDate: v.optional(v.number()),
        endDate: v.optional(v.number()),
      })
    ),
    paginationOpts: paginationOptsValidator,
  },
  returns: v.object({
    page: v.array(
      v.object({
        _id: v.id("platformCostAlerts"),
        alertType: v.string(),
        severity: v.string(),
        message: v.string(),
        metadata: v.optional(v.any()),
        createdAt: v.number(),
        acknowledged: v.boolean(),
        acknowledgedAt: v.optional(v.number()),
        acknowledgedBy: v.optional(v.id("user")),
      })
    ),
    isDone: v.boolean(),
    continueCursor: v.string(),
  }),
  handler: async (ctx, args) => {
    await verifyPlatformStaff(ctx);
    // Implementation
  },
});
```

### M4 Execution Order

**CRITICAL: Read these files IN ORDER before implementing:**

1. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M1_LESSONS_LEARNED.md
2. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M2_LESSONS_LEARNED.md
3. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M3_LESSONS_LEARNED.md
4. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/phases/PHASE_M4.json (FULL DETAILS)

**Implementation steps:**

1. Create /Users/neil/Documents/GitHub/PDP/packages/backend/convex/models/voicePipelineAlerts.ts
2. Implement verifyPlatformStaff helper function (copy from M3)
3. Implement checkPipelineHealth with all 6 health checks
   a. Query voicePipelineCounters for real-time metrics
   b. Query voicePipelineMetricsSnapshots for 7-day latency baseline
   c. Query voiceNoteArtifacts for queue depth
   d. Query voiceNoteEntityResolutions for disambiguation backlog
   e. Query aiServiceHealth for circuit breaker state
   f. Query voicePipelineEvents for last artifact_received timestamp (inactivity check)
   g. Perform all 6 checks with safe division and proper thresholds
   h. Deduplicate alerts before inserting
   i. Return summary
4. Implement getActiveAlerts query
5. Implement acknowledgeAlert mutation
6. Implement getAlertHistory query with pagination
7. Add cron job to /Users/neil/Documents/GitHub/PDP/packages/backend/convex/crons.ts
8. Run codegen: `npx -w packages/backend convex codegen`
9. Run type check: `npm run check-types`
10. Test via Convex dashboard (force conditions, verify alerts created)

### M4 Testing Checklist

**Manual testing via Convex dashboard:**

- [ ] Force high failure rate → run checkPipelineHealth → verify PIPELINE_HIGH_FAILURE_RATE alert created
- [ ] Call getActiveAlerts → verify alert appears
- [ ] Call acknowledgeAlert → verify alert marked acknowledged
- [ ] Run checkPipelineHealth again → verify doesn't create duplicate (deduplication works)
- [ ] Create many active artifacts → verify PIPELINE_HIGH_QUEUE_DEPTH alert
- [ ] Set aiServiceHealth.circuitBreakerState='open' → verify PIPELINE_CIRCUIT_BREAKER_OPEN alert (severity: critical)
- [ ] Create many disambiguation resolutions → verify PIPELINE_DISAMBIGUATION_BACKLOG alert
- [ ] Stop creating artifacts for 60+ minutes → verify PIPELINE_INACTIVITY alert
- [ ] Test latency spike: manually create snapshot with high latency → verify PIPELINE_HIGH_LATENCY alert
- [ ] Deploy cron → wait 5 minutes → verify runs automatically in Convex dashboard

### M4 Success Criteria

**From PRD (all must pass):**

- ✅ voicePipelineAlerts.ts created with 4 functions
- ✅ checkPipelineHealth runs successfully (6 health checks)
- ✅ All 6 alert types can be triggered
- ✅ Alert deduplication works (no duplicate alerts)
- ✅ getActiveAlerts returns only unacknowledged PIPELINE_* alerts
- ✅ acknowledgeAlert marks alert as acknowledged
- ✅ getAlertHistory returns paginated historical alerts
- ✅ Cron job added to crons.ts (every 5 minutes)
- ✅ Cron runs successfully in Convex dashboard
- ✅ Safe division: failure rate calculation handles divide-by-zero
- ✅ Latency baseline calculated from 168 hourly snapshots (7 days)
- ✅ All alert functions verify isPlatformStaff authorization
- ✅ Codegen passes
- ✅ Type check passes

---

## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
## PHASE M5 - Dashboard UI (CURRENT PHASE)
## ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

**Phase Start:** 2026-02-17
**Phase Goal:** Main monitoring dashboard UI with flow graph, real-time status cards, and activity feed
**PRD:** /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/phases/PHASE_M5.json
**Dependencies:** M1 ✅ | M2 ✅ | M3 ✅ | M4 ✅

### Phase M5 Overview

**What we're building:**
- Route structure at /platform/voice-monitoring
- Dashboard overview page with 3 sections:
  1. Pipeline Flow Graph (5 stages, SVG-based)
  2. Real-Time Status Cards (6 metrics)
  3. Recent Activity Feed (last 20 events)
- Tab navigation layout (8 tabs)
- Platform staff authorization
- Real-time Convex subscriptions

**Files to create:**
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/layout.tsx (client component)
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/page.tsx (client component)
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/_components/PipelineFlowGraph.tsx
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/_components/StatusCards.tsx
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/_components/ActivityFeed.tsx
- 6 placeholder pages for tabs: artifacts/, metrics/, events/, pipeline/, alerts/, settings/

**Files to modify:**
- /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/page.tsx (add Voice Monitoring link, remove v2-claims)

### US-VNM-008: Build Dashboard Overview UI

**Functions to implement:**

1. **layout.tsx** (Client Component)
   - USE CLIENT directive ('use client')
   - NOT server component (parent /platform/layout.tsx is client)
   - useCurrentUser() hook for auth (from context, zero queries)
   - Redirect to /platform if not platform staff
   - Tab navigation bar with 8 tabs using Link + usePathname()
   - Do NOT use shadcn/ui Tabs component (designed for state, not URL routing)
   - Breadcrumb: Platform > Voice Monitoring
   - Render {children}

2. **page.tsx** (Client Component)
   - USE CLIENT directive ('use client')
   - Three useQuery calls (ALL at page level):
     - `api.models.voicePipelineMetrics.getRealTimeMetrics()` with skip pattern
     - `api.models.voicePipelineEvents.getRecentEvents({ filters: {}, paginationOpts: { numItems: 20, cursor: null } })` with skip
     - `api.models.voicePipelineAlerts.getActiveAlerts()` with skip
   - Pass data as props to components (NO queries in components)
   - Render PipelineFlowGraph, StatusCards, ActivityFeed
   - Show skeleton loaders while data loading

3. **PipelineFlowGraph** (Component)
   - TWO inline SVG variants (horizontal desktop, vertical mobile)
   - Toggle via Tailwind: `hidden md:block` and `block md:hidden`
   - 5 pipeline stages with real-time counts
   - Color logic: green (active), gray (zero), red (failures detected)
   - ViewBox for responsive scaling
   - Arrowhead markers in <defs>
   - Prepared for M8 click-to-navigate (onClick handler stub)

4. **StatusCards** (Component)
   - Grid of 6 cards with responsive layout: `grid-cols-1 md:grid-cols-2 lg:grid-cols-3`
   - Query counters by counterType, access currentValue
   - Card 1: Active Artifacts (Activity icon)
   - Card 2: Completed Today (CheckCircle icon)
   - Card 3: Failed Today (XCircle icon, red if > 10%)
   - Card 4: Avg Latency (Clock icon)
   - Card 5: AI Service Status (Cpu icon, color by state)
   - Card 6: Total Cost Today (DollarSign icon)
   - Each card handles undefined props with inline Skeleton

5. **ActivityFeed** (Component)
   - List of last 20 events
   - Relative timestamps using date-fns
   - Event type icons (mapping provided in implementation guide)
   - Human-readable messages
   - Metadata badges
   - Empty state: "No recent activity"
   - ScrollArea component from shadcn/ui

6. **Platform Hub Update**
   - Add Voice Monitoring card with link
   - Remove v2-claims link (moved to artifacts grid in M6)

### M5 Critical Patterns (READ BEFORE IMPLEMENTING!)

**1. Client Component Pattern (MANDATORY for layout.tsx and page.tsx)**

**CRITICAL:** The parent `/platform/layout.tsx` is a CLIENT component. You CANNOT nest server components inside client layouts.

```typescript
// ✅ CORRECT: Client component
"use client";

import { useCurrentUser } from "@/hooks/useCurrentUser";

export default function VoiceMonitoringLayout({ children }) {
  const { user } = useCurrentUser();

  if (!user?.isPlatformStaff) {
    redirect("/platform");
  }

  // Tab navigation with Link + usePathname()
}
```

**2. Tab Navigation Pattern (NOT shadcn/ui Tabs)**

**WRONG (PRD suggestion):**
```typescript
// ❌ shadcn/ui Tabs for URL routing
<Tabs defaultValue="overview">
  <TabsList>
    <TabsTrigger value="overview">Overview</TabsTrigger>
  </TabsList>
  <TabsContent value="overview">{children}</TabsContent>
</Tabs>
```

**CORRECT:**
```typescript
// ✅ Link + usePathname for URL routing
"use client";
import Link from "next/link";
import { usePathname } from "next/navigation";

const pathname = usePathname();
const isActive = (path: string) => {
  if (path === "/platform/voice-monitoring") {
    return pathname === path;
  }
  return pathname.startsWith(path);
};

<div className="border-b">
  <nav className="flex space-x-4">
    <Link
      href="/platform/voice-monitoring"
      className={isActive("/platform/voice-monitoring") ? "active" : ""}
    >
      Overview
    </Link>
    <Link
      href="/platform/voice-monitoring/artifacts"
      className={isActive("/platform/voice-monitoring/artifacts") ? "active" : ""}
    >
      Artifacts
    </Link>
    {/* More tabs... */}
  </nav>
</div>
```

**3. Query Lifting Pattern (MANDATORY)**

**WRONG:**
```typescript
// ❌ Queries inside components (N+1 problem)
function StatusCards() {
  const metrics = useQuery(api.models.voicePipelineMetrics.getRealTimeMetrics);
  // ...
}
```

**CORRECT:**
```typescript
// ✅ Query at page level, pass as props
function Page() {
  const metrics = useQuery(
    api.models.voicePipelineMetrics.getRealTimeMetrics,
    isStaff ? {} : "skip"
  );

  return <StatusCards metrics={metrics} />;
}

function StatusCards({ metrics }) {
  if (!metrics) return <Skeleton />;
  // Use metrics
}
```

**4. Counter Schema Query Pattern**

**WRONG:**
```typescript
// ❌ Accessing non-existent fields
const completed = metrics.completed;
```

**CORRECT:**
```typescript
// ✅ Query counters by type, access currentValue
// From M4 lessons: counters have { counterType, currentValue }
// getRealTimeMetrics already aggregates these for you
const completed = metrics?.artifactsCompleted1h ?? 0;
```

**5. Pagination Pattern for Events**

**WRONG:**
```typescript
// ❌ usePaginatedQuery (not compatible)
const events = usePaginatedQuery(api.models.voicePipelineEvents.getRecentEvents, {
  filters: {},
  initialNumItems: 20
});
```

**CORRECT:**
```typescript
// ✅ Regular useQuery with cursor: null
const eventsResult = useQuery(
  api.models.voicePipelineEvents.getRecentEvents,
  isStaff ? { filters: {}, paginationOpts: { numItems: 20, cursor: null } } : "skip"
);

const events = eventsResult?.page ?? [];
```

**6. Responsive SVG Pattern**

**CRITICAL:** Two separate SVG variants for horizontal (desktop) and vertical (mobile) layouts.

```typescript
// ✅ Horizontal (desktop)
<svg
  viewBox="0 0 1200 300"
  className="hidden md:block w-full h-auto"
>
  {/* Horizontal layout */}
</svg>

// ✅ Vertical (mobile)
<svg
  viewBox="0 0 400 900"
  className="block md:hidden w-full h-auto"
>
  {/* Vertical layout */}
</svg>
```

**7. Loading State Pattern**

**Each component handles own undefined props:**
```typescript
function StatusCards({ metrics }) {
  if (!metrics) {
    return (
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
        {Array.from({ length: 6 }).map((_, i) => (
          <Card key={i}>
            <CardContent className="p-6">
              <Skeleton className="h-20" />
            </CardContent>
          </Card>
        ))}
      </div>
    );
  }

  // Render actual cards
}
```

**8. Atomic Imports (MANDATORY from M1-M4)**

```typescript
// ✅ CORRECT: Import + usage in SAME edit
import { Card } from "@/components/ui/card";

export default function Page() {
  return <Card>...</Card>;  // Used immediately
}
```

**9. Responsive Grid Pattern**

```typescript
// ✅ Mobile-first Tailwind classes
<div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
  {/* 1 column on mobile, 2 on tablet, 3 on desktop */}
</div>
```

**10. Tab Navigation Responsive (Horizontal Scroll)**

```typescript
// ✅ Horizontal scroll on mobile
<div className="border-b overflow-x-auto">
  <nav className="flex space-x-4 min-w-max px-4">
    {/* Tabs */}
  </nav>
</div>
```

### M5 Gotchas to Avoid

1. **❌ Don't use server components for layout.tsx**
   - Parent /platform/layout.tsx is client component
   - Must use 'use client' directive

2. **❌ Don't use shadcn/ui Tabs for URL routing**
   - Tabs component manages internal state, not URLs
   - Use Link + usePathname instead

3. **❌ Don't query inside components**
   - Causes N+1 subscriptions
   - Lift all useQuery to page level

4. **❌ Don't use usePaginatedQuery for getRecentEvents**
   - Custom pagination format, not Convex native
   - Use regular useQuery with cursor: null

5. **❌ Don't forget responsive SVG variants**
   - Need both horizontal and vertical SVGs
   - Toggle via hidden/block classes

6. **❌ Don't forget skip pattern on queries**
   - Query only when user is platform staff
   - `isStaff ? args : "skip"`

7. **❌ Don't access counter fields directly**
   - Query by counterType, access currentValue
   - getRealTimeMetrics already aggregates for you

8. **❌ Don't test only on desktop**
   - MUST test at 375px minimum (iPhone SE)
   - Use Chrome DevTools responsive mode

### M5 Execution Order

**CRITICAL: Read these files IN ORDER before implementing:**

1. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M1_LESSONS_LEARNED.md
2. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M2_LESSONS_LEARNED.md
3. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M3_LESSONS_LEARNED.md
4. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/context/M4_LESSONS_LEARNED.md
5. /Users/neil/Documents/GitHub/PDP/scripts/ralph/prds/voice-monitor-harness/phases/PHASE_M5.json (FULL DETAILS)
6. /Users/neil/Documents/GitHub/PDP/scripts/ralph/agents/output/m5-implementation-guide.md (COMPLETE CODE EXAMPLES)

**Implementation steps:**

1. Create placeholder pages (artifacts/, metrics/, events/, pipeline/, alerts/, settings/) with "Coming in M6/M7/M8" messages
2. Create /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/layout.tsx
   - Client component ('use client')
   - useCurrentUser() hook
   - Redirect if not platform staff
   - Tab navigation with Link + usePathname()
3. Create /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/voice-monitoring/page.tsx
   - Client component ('use client')
   - Three useQuery calls at top level with skip pattern
   - Pass data as props to components
   - Show loading skeletons
4. Create PipelineFlowGraph component
   - Two SVG variants (horizontal + vertical)
   - Toggle via Tailwind classes
   - 5 stages with color logic
5. Create StatusCards component
   - 6 cards with responsive grid
   - Each card handles undefined with Skeleton
   - Query counter data from metrics prop
6. Create ActivityFeed component
   - Event list with icons and timestamps
   - Empty state
   - ScrollArea component
7. Update /Users/neil/Documents/GitHub/PDP/apps/web/src/app/platform/page.tsx
   - Add Voice Monitoring link
   - Remove v2-claims link
8. Run type check: npm run check-types
9. Test with dev-browser at 375px, 768px, 1024px
10. Test real-time updates with voice note creation

### M5 Testing Checklist

**Manual testing via dev-browser:**

- [ ] Navigate to /platform/voice-monitoring as platform staff → verify dashboard loads
- [ ] Navigate as non-staff → verify redirect to /platform
- [ ] Verify tab navigation shows 8 tabs (horizontal scroll on mobile)
- [ ] Verify flow graph displays 5 stages (horizontal on desktop, vertical on mobile)
- [ ] Verify 6 status cards show real-time data
- [ ] Verify activity feed shows last 20 events
- [ ] Create voice note → verify dashboard updates in real-time (< 10 seconds)
- [ ] Verify loading states show skeletons
- [ ] Test mobile layout at 375px width
- [ ] Test tablet layout at 768px width
- [ ] Test desktop layout at 1024px width
- [ ] Click tab links → verify navigation works
- [ ] Verify Voice Monitoring link on platform hub
- [ ] Verify v2-claims link removed

### M5 Success Criteria

**From PRD (all must pass):**

- ✅ Route created at /platform/voice-monitoring
- ✅ Layout with tab navigation (8 tabs)
- ✅ Page with 3 useQuery calls
- ✅ PipelineFlowGraph displays 5 stages
- ✅ StatusCards shows 6 metrics
- ✅ ActivityFeed shows 20 events
- ✅ Platform hub has Voice Monitoring link
- ✅ v2-claims link removed
- ✅ Platform staff auth enforced
- ✅ Real-time updates work
- ✅ Loading states show
- ✅ Responsive design works
- ✅ Type check passes

---

## What Ralph should do for M4 (ARCHIVED - PHASE COMPLETE):

**BEFORE starting implementation:**
1. Read M1_LESSONS_LEARNED.md
2. Read M2_LESSONS_LEARNED.md
3. Read M3_LESSONS_LEARNED.md
4. Read PHASE_M4.json for full implementation details

**During implementation:**
1. Use full file paths (/Users/neil/Documents/GitHub/PDP/...)
2. Copy verifyPlatformStaff helper from voicePipelineRetry.ts
3. Handle divide-by-zero in failure rate calculation
4. Implement alert deduplication (check existing unacknowledged alerts)
5. Use .collect() and slice for latency baseline (not .take(168))
6. Use voicePipelineCounters for real-time metrics (NOT event scans)
7. Add platform staff auth to all queries/mutations
8. Use correct severity levels (critical/high/medium/low)
9. Test each alert type individually via Convex dashboard

**After implementation:**
1. Run codegen: `npx -w packages/backend convex codegen`
2. Run type check: `npm run check-types`
3. Test all 6 alert types via Convex dashboard
4. Verify cron visible and runs every 5 minutes
5. Verify alert deduplication works
6. Update this progress log with results

---

## 2026-02-16 22:00 - US-VNM-007 - Build Pipeline Alerts Backend
**Iteration**: 3
**Commit**: 11de6a7a86665b96032dbca2bf2ff26aa6d64cdb
**Session**: 8072bdfe-146c-402f-bdd1-7ccde7f998ed
**Status**: Complete

### What was implemented
- Created voicePipelineAlerts.ts with 4 functions (1 health check internal mutation + 3 platform staff queries/mutations)
- Implemented checkPipelineHealth internalMutation with all 6 health checks:
  1. Failure Rate: failures / (completed + failures) > 0.10 → PIPELINE_HIGH_FAILURE_RATE (severity: high)
  2. Latency Spike: current latency > 2x 7-day avg → PIPELINE_HIGH_LATENCY (severity: medium)
  3. Queue Depth: active artifacts > 50 → PIPELINE_HIGH_QUEUE_DEPTH (severity: medium)
  4. Disambiguation Backlog: needs_disambiguation > 100 → PIPELINE_DISAMBIGUATION_BACKLOG (severity: low)
  5. Circuit Breaker: state='open' or 'half_open' → PIPELINE_CIRCUIT_BREAKER_OPEN (severity: critical)
  6. Pipeline Inactivity: no artifacts received in 60+ min → PIPELINE_INACTIVITY (severity: low)
- Implemented alert deduplication: checks for existing unacknowledged alert of same type before inserting
- Implemented getActiveAlerts query: returns unacknowledged PIPELINE_* alerts sorted by severity
- Implemented acknowledgeAlert mutation: marks alert as acknowledged with timestamp and user ID
- Implemented getAlertHistory query: paginated alerts with filters (severity, alertType, date range)
- Extended platformCostAlerts schema to support PIPELINE_* alert types and 4 severity levels
- Added metadata field to platformCostAlerts (v.optional(v.any()))
- Added createdAt field (optional for backward compat with existing timestamp field)
- Added cron job: check-pipeline-health (runs every 5 minutes)

### Files changed
- packages/backend/convex/models/voicePipelineAlerts.ts (+610, new file)
- packages/backend/convex/schema.ts (+21, -7) - Extended platformCostAlerts
- packages/backend/convex/crons.ts (+7, -0) - Added health check cron

### Quality checks
- ✅ Type check: passed (codegen succeeded)
- ✅ Linting: passed (1 warning in M4 files, acceptable)
- ✅ Pre-commit hooks: passed
- ✅ Safe division: All rate calculations check denominator > 0
- ✅ Alert deduplication: Checks for existing unacknowledged alert before inserting
- ✅ Platform staff auth: All queries/mutations verify isPlatformStaff
- ✅ Index usage: All queries use .withIndex()
- ✅ Fire-and-forget pattern: Not needed in health check (internal mutation, non-blocking)

### **Learnings for future iterations** ⚠️ CRITICAL

**Patterns discovered:**
- voicePipelineCounters schema: use `counterType` + `currentValue`, NOT individual fields like `completed`/`failures`
- Query counters by type: `.withIndex("by_counterType_and_org", q => q.eq("counterType", "artifacts_completed_1h"))`
- voicePipelineMetricsSnapshots index: `by_periodType_and_start` (NOT `by_periodType_and_windowEnd`)
- voiceNoteArtifacts index: `by_status_and_createdAt` (NOT `by_status` alone)
- platformCostAlerts acknowledgedBy: `v.optional(v.string())` (NOT `v.id("user")`)
- Schema evolution: Made triggerValue/thresholdValue/timestamp optional for backward compat
- TypeScript `as const` for status arrays: prevents type widening, enables literal type inference

**Gotchas encountered:**
- Initial attempt used non-existent counter fields (counter.completed, counter.failures)
- Fixed by querying specific counterTypes and accessing currentValue
- Initial attempt used wrong snapshot index (by_periodType_and_windowEnd)
- Fixed to use by_periodType_and_start (correct index name)
- Initial attempt used `by_status` index on voiceNoteArtifacts (doesn't exist)
- Fixed to use `by_status_and_createdAt` (composite index)
- TypeScript error: `status` type widened from literal to string in loop
- Fixed with `as const` assertion on status array
- Import path error: Used `../lib/authComponent` instead of `../auth`
- Fixed to match existing import pattern from other models

**Dependencies found:**
- voicePipelineCounters: Real-time metrics (O(1) counter reads)
- voicePipelineMetricsSnapshots: Historical latency baseline (7-day rolling average)
- voiceNoteArtifacts: Queue depth calculation (active statuses)
- voiceNoteEntityResolutions: Disambiguation backlog count
- aiServiceHealth: Circuit breaker state detection
- voicePipelineEvents: Last artifact_received timestamp (inactivity check)
- platformCostAlerts: Alert storage (extended schema)

**What to do next:**
- [ ] Manual testing via Convex dashboard (as documented in PHASE_M4.json)
- [ ] Force high failure rate → verify PIPELINE_HIGH_FAILURE_RATE alert
- [ ] Force latency spike → verify PIPELINE_HIGH_LATENCY alert
- [ ] Create 51+ active artifacts → verify PIPELINE_HIGH_QUEUE_DEPTH alert
- [ ] Create 101+ disambiguation resolutions → verify PIPELINE_DISAMBIGUATION_BACKLOG alert
- [ ] Set circuit breaker to open → verify PIPELINE_CIRCUIT_BREAKER_OPEN alert (severity: critical)
- [ ] Stop creating artifacts for 60+ min → verify PIPELINE_INACTIVITY alert
- [ ] Test getActiveAlerts → verify sorted by severity
- [ ] Test acknowledgeAlert → verify alert marked acknowledged
- [ ] Test getAlertHistory with filters → verify pagination works
- [ ] Test deduplication: acknowledge alert → run health check again → verify no duplicate
- [ ] Verify cron visible in Convex dashboard
- [ ] Deploy cron → wait 5 minutes → verify runs automatically

**Mistakes made:**
- Initially assumed voicePipelineCounters had completed/failures fields (wrong - uses counterType)
- Initially used wrong index name for snapshots (by_periodType_and_windowEnd vs by_periodType_and_start)
- Initially forgot `as const` for status array (TypeScript couldn't infer literal types)
- Initially used wrong import path for authComponent

**M4 PRD Compliance:**
✅ All 4 functions from PHASE_M4.json implemented
✅ checkPipelineHealth with all 6 health checks
✅ Alert deduplication implemented (checks for existing unacknowledged alerts)
✅ getActiveAlerts filters for PIPELINE_* and sorts by severity
✅ acknowledgeAlert updates acknowledged, acknowledgedAt, acknowledgedBy
✅ getAlertHistory with pagination and filters
✅ Cron job added (check-pipeline-health, every 5 minutes)
✅ Safe division for failure rate calculation
✅ Latency baseline from 168 hourly snapshots (7 days)
✅ Platform staff auth on all queries/mutations
✅ Codegen passes
✅ Type check passes (pre-existing errors in other files only)
✅ Extended platformCostAlerts schema (6 new alert types, 3 new severity levels, metadata field)

**Key Implementation Details:**

1. **Counter-Based Metrics Query:**
   ```typescript
   const completedCounter = await ctx.db
     .query("voicePipelineCounters")
     .withIndex("by_counterType_and_org", (q) =>
       q.eq("counterType", "artifacts_completed_1h").eq("organizationId", undefined)
     )
     .first();
   const totalCompleted = completedCounter?.currentValue ?? 0;
   ```

2. **Latency Baseline Calculation:**
   ```typescript
   const hourlySnapshots = await ctx.db
     .query("voicePipelineMetricsSnapshots")
     .withIndex("by_periodType_and_start", (q) => q.eq("periodType", "hourly"))
     .order("desc")
     .collect();
   const last168Snapshots = hourlySnapshots.slice(0, 168);
   const historicalAvgLatency = last168Snapshots.reduce(...) / last168Snapshots.length;
   ```

3. **Alert Deduplication:**
   ```typescript
   async function hasUnacknowledgedAlert(ctx: MutationCtx, alertType: string): Promise<boolean> {
     const existingAlerts = await ctx.db
       .query("platformCostAlerts")
       .withIndex("by_acknowledged", (q) => q.eq("acknowledged", false))
       .collect();
     return existingAlerts.some((alert) => alert.alertType === alertType);
   }
   ```

4. **Severity Ordering:**
   ```typescript
   const severityOrder: Record<string, number> = {
     critical: 0,
     high: 1,
     medium: 2,
     low: 3,
   };
   pipelineAlerts.sort((a, b) => {
     const severityDiff = severityOrder[a.severity] - severityOrder[b.severity];
     if (severityDiff !== 0) return severityDiff;
     return b.createdAt - a.createdAt; // Newest first
   });
   ```

5. **Error Handling in Cron:**
   ```typescript
   try {
     // Health checks...
   } catch (error) {
     console.error("Health check error:", error);
     // Don't throw - return successfully to prevent cron retries
     return { alertsCreated: 0, checksPerformed: ["error_occurred"] };
   }
   ```

---

