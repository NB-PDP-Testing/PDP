{
  "project": "Coach-Parent AI Summaries - Phase 5 (Progressive Automation)",
  "branchName": "ralph/coach-parent-summaries-p5",
  "description": "Progressive automation with preview mode, supervised auto-approval, cost optimization, and learning loop. Builds on Phase 1-4 infrastructure.",
  "philosophyAndGoals": {
    "corePhilosophy": "Coaches always feel in full control. AI automation is transparent, reversible, and learns from coach behavior. We prompt coaches with support when patterns suggest they're ready for more automation.",
    "keyPrinciples": [
      "Transparency first: Show what AI would do BEFORE doing it (preview mode)",
      "Safety nets: 1-hour revoke window for auto-approved messages",
      "Progressive trust: Preview → Supervised → Full automation (3 stages)",
      "Learn from overrides: Capture WHY coaches suppress, not just IF",
      "Cost conscious: 90% savings via prompt caching before scale",
      "Personalized: Adaptive thresholds per coach based on their patterns"
    ],
    "successMetrics": {
      "week2": "40% preview mode agreement rate (coaches would approve what AI suggested)",
      "week4": "30%+ auto-approval rate, <5% revocation rate",
      "week6": "80%+ cache hit rate, <$0.01/message cost",
      "week8": "Decreasing suppression rates as AI learns from feedback"
    }
  },
  "industryResearch": {
    "zendesk": "60-70% confidence threshold in production, 50-70% is sweet spot",
    "githubCopilot": "21-23% acceptance rate is excellent, track 'accepted and retained' not just 'accepted'",
    "googleSmartReply": "Preview suggestions before auto-send, 3-4 stages not instant automation",
    "anthropic": "Prompt caching reduces costs 90% by caching static context",
    "stripe": "Circuit breaker pattern: detect degradation and gracefully fallback"
  },
  "implementationOrder": [
    "Phase 1: Transparent Preview Mode (Weeks 1-2) - Stories US-001 to US-005",
    "Phase 2: Supervised Auto-Approval (Weeks 3-4) - Stories US-006 to US-011",
    "Phase 3: Cost Optimization (Weeks 5-6) - Stories US-012 to US-015",
    "Phase 4: Learning Loop (Weeks 7-8) - Stories US-016 to US-020"
  ],
  "dependencies": {
    "requiredPhases": ["Phase 1", "Phase 2", "Phase 3", "Phase 4"],
    "requiredTables": [
      "coachParentSummaries - Has all fields including publicSummary.confidenceScore",
      "coachTrustLevels - Platform-wide trust with currentLevel, preferredLevel, totalApprovals, totalSuppressed"
    ],
    "requiredActions": [
      "generateParentSummary - Already generates confidenceScore (currently unused)",
      "classifyInsightSensitivity - Classifies as normal/injury/behavior"
    ],
    "criticalGap": "Trust levels built but don't automate anything. Confidence scores generated but hidden. P5 connects the dots."
  },
  "userStories": [
    {
      "id": "US-001",
      "title": "Add preview mode fields to coachTrustLevels schema",
      "description": "As a coach, the system tracks my preview mode progress.",
      "phase": "1: Preview Mode",
      "acceptanceCriteria": [
        "Add previewModeStats to coachTrustLevels table: v.optional(v.object({ wouldAutoApproveSuggestions: v.number(), coachApprovedThose: v.number(), coachRejectedThose: v.number(), agreementRate: v.number(), startedAt: v.number(), completedAt: v.optional(v.number()) }))",
        "Add confidenceThreshold field: v.optional(v.number()) with range 0.5-1.0",
        "Run: npx -w packages/backend convex codegen",
        "Typecheck passes"
      ],
      "priority": 1,
      "passes": false,
      "notes": "Preview mode shows what AI WOULD do without doing it. Builds trust before automation. Industry pattern: Google Smart Reply, GitHub Copilot."
    },
    {
      "id": "US-002",
      "title": "Add wouldAutoApprove calculation to getCoachPendingSummaries",
      "description": "As a coach, I see which summaries would auto-approve.",
      "acceptanceCriteria": [
        "Edit getCoachPendingSummaries query in coachParentSummaries.ts",
        "For each pending summary, fetch coach's trust level and confidenceThreshold (default 0.7)",
        "Calculate wouldAutoApprove: sensitivityCategory === 'normal' AND currentLevel >= 2 AND confidenceScore >= threshold",
        "Add wouldAutoApprove boolean to returned summary objects",
        "Update returns validator to include wouldAutoApprove field",
        "Typecheck passes"
      ],
      "priority": 2,
      "passes": false,
      "notes": "This is prediction only - nothing auto-approves yet. Shows coaches what WOULD happen. Use Math.min(currentLevel, preferredLevel ?? currentLevel) to respect coach preferences."
    },
    {
      "id": "US-003",
      "title": "Add confidence visualization to SummaryApprovalCard",
      "description": "As a coach, I see AI confidence scores on approval cards.",
      "acceptanceCriteria": [
        "Edit apps/web/src/app/orgs/[orgId]/coach/voice-notes/components/summary-approval-card.tsx",
        "Import Progress component from @/components/ui/progress",
        "Display summary.publicSummary.confidenceScore as percentage with progress bar",
        "Color coding: <60% red, 60-79% amber, 80%+ green",
        "Show text: 'AI Confidence: {score}%'",
        "Position below summary content, above original insight collapsible",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": false,
      "notes": "Confidence scores are already generated (generateParentSummary action) but currently hidden. Making them visible is transparency-first principle."
    },
    {
      "id": "US-004",
      "title": "Add preview mode indicator to SummaryApprovalCard",
      "description": "As a coach in preview mode, I see what AI would do.",
      "acceptanceCriteria": [
        "In SummaryApprovalCard, accept wouldAutoApprove prop from parent",
        "If wouldAutoApprove === true, show Badge with Sparkles icon: 'AI would auto-send this'",
        "Badge variant: 'secondary' with blue/purple accent",
        "Position near confidence score",
        "If wouldAutoApprove === false, show subtle text: 'Requires manual review'",
        "Import Sparkles from lucide-react",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": false,
      "notes": "Visual feedback loop. Coaches see patterns: 'Oh, AI auto-sends high confidence normal summaries.' Builds mental model before automation."
    },
    {
      "id": "US-005",
      "title": "Track preview mode statistics",
      "description": "As a coach, the system learns my preview mode agreement rate.",
      "acceptanceCriteria": [
        "Edit approveSummary mutation in coachParentSummaries.ts",
        "Before updating trust metrics, check if coach is in preview mode (previewModeStats exists and completedAt is null)",
        "If wouldAutoApprove was true and coach approved: increment coachApprovedThose",
        "If wouldAutoApprove was true and coach suppressed: increment coachRejectedThose",
        "Recalculate agreementRate: coachApprovedThose / wouldAutoApproveSuggestions",
        "If wouldAutoApproveSuggestions >= 20: set completedAt, preview mode complete",
        "Add wouldAutoApprove field to summary schema if needed for tracking",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": false,
      "notes": "20-message preview period. Industry insight: GitHub Copilot tracks acceptance patterns before suggesting features. Agreement rate >70% suggests coach trusts AI."
    },
    {
      "id": "US-006",
      "title": "Add auto-approval decision fields to coachParentSummaries schema",
      "description": "As a developer, I need to track auto-approval decisions.",
      "phase": "2: Supervised Auto-Approval",
      "acceptanceCriteria": [
        "Add autoApprovalDecision to coachParentSummaries: v.optional(v.object({ shouldAutoApprove: v.boolean(), reason: v.string(), tier: v.union(v.literal('auto_send'), v.literal('manual_review'), v.literal('flagged')), decidedAt: v.number() }))",
        "Add scheduledDeliveryAt: v.optional(v.number()) for 1-hour revoke window",
        "Add revokedAt: v.optional(v.number()), revokedBy: v.optional(v.string()), revocationReason: v.optional(v.string())",
        "Run: npx -w packages/backend convex codegen",
        "Typecheck passes"
      ],
      "priority": 6,
      "passes": false,
      "notes": "Audit trail for auto-approval. tier field enables future enhancements (immediate send vs delayed vs flagged for senior review)."
    },
    {
      "id": "US-007",
      "title": "Create autoApprovalDecision lib",
      "description": "As a developer, I need pure logic for auto-approval decisions.",
      "acceptanceCriteria": [
        "Create packages/backend/convex/lib/autoApprovalDecision.ts",
        "Export interface AutoApprovalDecision { shouldAutoApprove: boolean; reason: string; tier: 'auto_send' | 'manual_review' | 'flagged'; }",
        "Export function decideAutoApproval(trustLevel: TrustLevel, summary: { confidenceScore: number; sensitivityCategory: string }): AutoApprovalDecision",
        "Logic: NEVER auto-approve if sensitivityCategory !== 'normal'",
        "Logic: Require effectiveLevel >= 2 (use Math.min(currentLevel, preferredLevel ?? currentLevel))",
        "Logic: Level 2 requires confidenceScore >= (confidenceThreshold ?? 0.7)",
        "Logic: Level 3 auto-approves all normal (full automation opt-in)",
        "Include descriptive reasons: 'injury requires manual review', 'confidence 65% below 70% threshold', 'Level 3 full automation'",
        "Typecheck passes"
      ],
      "priority": 7,
      "passes": false,
      "notes": "Pure function, fully testable. Reference trustLevelCalculator.ts for pattern. Default 70% threshold balances volume and accuracy (Zendesk uses 60-70%)."
    },
    {
      "id": "US-008",
      "title": "Implement auto-approval in createParentSummary",
      "description": "As the system, eligible summaries auto-approve with 1-hour delay.",
      "acceptanceCriteria": [
        "Edit createParentSummary internalMutation in coachParentSummaries.ts",
        "Import decideAutoApproval from lib/autoApprovalDecision",
        "Fetch coach's trust level using by_coach_org index",
        "Call decideAutoApproval with trust level and summary data",
        "Store decision in autoApprovalDecision field",
        "If shouldAutoApprove === true: status = 'auto_approved', approvedAt = Date.now(), approvedBy = 'system:auto', scheduledDeliveryAt = Date.now() + (60 * 60 * 1000)",
        "If shouldAutoApprove === false: status = 'pending_review' (existing behavior)",
        "Typecheck passes"
      ],
      "priority": 8,
      "passes": false,
      "notes": "1-hour revoke window = supervised automation. Industry pattern: allows coach to catch errors before parent sees. scheduledDeliveryAt enables future scheduled delivery job."
    },
    {
      "id": "US-009",
      "title": "Implement revokeSummary mutation",
      "description": "As a coach, I can revoke auto-approved summaries before delivery.",
      "acceptanceCriteria": [
        "Add revokeSummary mutation to coachParentSummaries.ts",
        "Args: summaryId (Id<'coachParentSummaries'>), reason (optional string)",
        "Use authComponent.safeGetAuthUser, verify coach owns summary",
        "Check summary.status === 'auto_approved' and viewedAt is null",
        "If already viewed: return { success: false, error: 'Summary already viewed by parent' }",
        "If not viewed: patch status to 'suppressed', set revokedAt, revokedBy, revocationReason",
        "Call updateTrustMetrics with action: 'suppressed' (counts as suppression)",
        "Returns: v.object({ success: v.boolean(), error: v.optional(v.string()) })",
        "Typecheck passes"
      ],
      "priority": 9,
      "passes": false,
      "notes": "Safety net. Coach catches error within 1 hour, can pull it back. After parent views, no revoke (audit trail intact). Revokes count as suppressions for trust metrics."
    },
    {
      "id": "US-010",
      "title": "Create AutoApprovedTab component",
      "description": "As a coach, I see recently auto-approved messages.",
      "acceptanceCriteria": [
        "Create apps/web/src/app/orgs/[orgId]/coach/voice-notes/components/auto-approved-tab.tsx",
        "Add 'use client' directive",
        "Props: { orgId: string; onSuccess: (msg: string) => void; onError: (msg: string) => void }",
        "Create getAutoApprovedSummaries query in coachParentSummaries.ts: args organizationId, returns summaries from last 7 days with status auto_approved or viewed where autoApprovalDecision.shouldAutoApprove === true",
        "Use useQuery to fetch auto-approved summaries",
        "Display in table: Player, Summary, Confidence, Sent At, Status (Pending Delivery / Delivered / Viewed), Revoke button",
        "Revoke button disabled if viewed or past 1 hour",
        "Typecheck passes"
      ],
      "priority": 10,
      "passes": false,
      "notes": "Dashboard for transparency. Coach sees what went out automatically. Can revoke if mistake caught early. Shows delivery status and parent engagement."
    },
    {
      "id": "US-011",
      "title": "Add AutoApprovedTab to voice notes dashboard",
      "description": "As a coach at level 2+, I see the auto-approved tab.",
      "acceptanceCriteria": [
        "Edit apps/web/src/app/orgs/[orgId]/coach/voice-notes/voice-notes-dashboard.tsx",
        "Import AutoApprovedTab component",
        "Add to tabs array conditionally: if trustLevel?.currentLevel >= 2",
        "Tab label: 'Auto-Sent' with count badge showing pending delivery count",
        "Position after Parents tab, before Insights tab",
        "Wire onSuccess and onError handlers",
        "Typecheck passes"
      ],
      "priority": 11,
      "passes": false,
      "notes": "Only visible to coaches who've earned automation (level 2+). Badge shows pending count to encourage review within revoke window."
    },
    {
      "id": "US-012",
      "title": "Add prompt caching to generateParentSummary action",
      "description": "As the platform, AI costs drop 90% via caching.",
      "phase": "3: Cost Optimization",
      "acceptanceCriteria": [
        "Edit generateParentSummary action in actions/coachParentSummaries.ts",
        "Update Anthropic client call to use prompt caching beta header: anthropic-beta: prompt-caching-2024-07-31",
        "Restructure messages array: [{ role: 'user', content: [{ type: 'text', text: systemPrompt, cache_control: { type: 'ephemeral' } }, { type: 'text', text: `Player: ${playerName}\\nSport: ${sport}` }, { type: 'text', text: `Insight: ${insight}` }] }]",
        "Cache system prompt (static, reused across requests)",
        "Cache player/sport context (static per player)",
        "Only insight is dynamic (no cache)",
        "Verify cache hits in response.usage.cache_read_input_tokens",
        "Typecheck passes"
      ],
      "priority": 12,
      "passes": false,
      "notes": "90% cost savings. Anthropic prompt caching: $0.50/M vs $5/M (90% discount) for cached content. Static prompts + player context cached, only insight varies. At 1000 msgs/mo: $25 → $2.50."
    },
    {
      "id": "US-013",
      "title": "Add aiUsageLog table to schema",
      "description": "As a developer, I need to track AI usage and costs.",
      "acceptanceCriteria": [
        "Add aiUsageLog table to schema.ts: organizationId (string), actionType (v.union of literals: 'generate_summary' | 'classify_sensitivity'), tokensInput (number), tokensOutput (number), tokensCached (number), costUsd (number), model (string), timestamp (number)",
        "Add indexes: by_org (organizationId), by_org_date (organizationId, timestamp)",
        "Run: npx -w packages/backend convex codegen",
        "Typecheck passes"
      ],
      "priority": 13,
      "passes": false,
      "notes": "Track every AI call with full cost breakdown. tokensCached enables measuring cache effectiveness. Cost formula: (tokensInput * $5/M) + (tokensOutput * $15/M) + (tokensCached * $0.50/M)."
    },
    {
      "id": "US-014",
      "title": "Log AI usage in actions",
      "description": "As the system, all AI calls are logged for cost tracking.",
      "acceptanceCriteria": [
        "Create logAIUsage internalMutation in new file: models/aiUsageLog.ts",
        "Args: organizationId, actionType, tokensInput, tokensOutput, tokensCached, model",
        "Calculate costUsd: (tokensInput - tokensCached) * 0.000005 + tokensCached * 0.0000005 + tokensOutput * 0.000015 (Claude Haiku rates)",
        "Insert aiUsageLog record",
        "Edit generateParentSummary and classifyInsightSensitivity actions",
        "After Anthropic API call, extract usage.input_tokens, usage.output_tokens, usage.cache_read_input_tokens ?? 0",
        "Call ctx.runMutation(internal.models.aiUsageLog.logAIUsage, {...})",
        "Typecheck passes"
      ],
      "priority": 14,
      "passes": false,
      "notes": "Every AI call tracked. Enables cost dashboards, alerts, optimization opportunities. cache_read_input_tokens only present if caching enabled (US-012)."
    },
    {
      "id": "US-015",
      "title": "Create AI usage dashboard query",
      "description": "As an org admin, I see AI usage and costs.",
      "acceptanceCriteria": [
        "Add getAIUsageSummary query to aiUsageLog.ts",
        "Args: organizationId, dateRange (default 30 days)",
        "Use by_org_date index to get logs in range",
        "Aggregate: totalCalls, totalCostUsd, cacheHitRate (tokensCached / totalTokensInput), costPerMessage",
        "Group by day for sparkline data",
        "Returns: v.object({ totalCalls: v.number(), totalCostUsd: v.number(), cacheHitRate: v.number(), costPerMessage: v.number(), dailyBreakdown: v.array(...) })",
        "Typecheck passes"
      ],
      "priority": 15,
      "passes": false,
      "notes": "Dashboard data. Show org admins: total cost, cache effectiveness (target 80%+), cost per message (target <$0.01). Daily breakdown enables trend spotting."
    },
    {
      "id": "US-016",
      "title": "Add override tracking fields to coachParentSummaries",
      "description": "As a coach, the system learns from my override decisions.",
      "phase": "4: Learning Loop",
      "acceptanceCriteria": [
        "Add overrideType to coachParentSummaries: v.optional(v.union(v.literal('coach_approved_low_confidence'), v.literal('coach_rejected_high_confidence'), v.literal('coach_edited'), v.literal('coach_revoked_auto')))",
        "Add overrideReason: v.optional(v.string())",
        "Add overrideFeedback: v.optional(v.object({ wasInaccurate: v.boolean(), wasTooSensitive: v.boolean(), timingWasWrong: v.boolean(), otherReason: v.optional(v.string()) }))",
        "Run: npx -w packages/backend convex codegen",
        "Typecheck passes"
      ],
      "priority": 16,
      "passes": false,
      "notes": "Learning signal. Track when coach disagrees with AI: approves low confidence, rejects high confidence, revokes auto-sent. Optional feedback captures WHY (pattern analysis)."
    },
    {
      "id": "US-017",
      "title": "Capture override data in suppressSummary",
      "description": "As a coach, suppressing gives feedback to improve AI.",
      "acceptanceCriteria": [
        "Edit suppressSummary mutation in coachParentSummaries.ts",
        "Add optional args: reason (string), feedback (object matching overrideFeedback schema)",
        "Determine overrideType: if confidenceScore >= 0.7 then 'coach_rejected_high_confidence', else null",
        "Store overrideType, overrideReason, overrideFeedback in summary record",
        "Show optional feedback form in UI (next story)",
        "Typecheck passes"
      ],
      "priority": 17,
      "passes": false,
      "notes": "Low friction - feedback is optional. But when provided, enables AI improvement. Pattern: 'AI thought this was good (75% confidence) but coach suppressed because timing was wrong.'"
    },
    {
      "id": "US-018",
      "title": "Add optional feedback to suppress action",
      "description": "As a coach, I can optionally explain why I suppressed.",
      "acceptanceCriteria": [
        "Edit SummaryApprovalCard, InjuryApprovalCard, BehaviorApprovalCard components",
        "Import Dialog, DialogContent, DialogHeader from @/components/ui/dialog",
        "On suppress button click: show dialog with checkboxes for feedback",
        "Checkboxes: 'Inaccurate', 'Too sensitive', 'Timing not right', text area for 'Other'",
        "Include 'Skip' button (closes dialog, suppresses without feedback)",
        "Include 'Suppress & Send Feedback' button (calls mutation with feedback)",
        "Make it quick: default is Skip, feedback is optional help",
        "Typecheck passes"
      ],
      "priority": 18,
      "passes": false,
      "notes": "Optional by design. Most coaches will skip. Those who engage provide valuable signal. Industry: GitHub Copilot prompts for feedback occasionally, not always."
    },
    {
      "id": "US-019",
      "title": "Create getCoachOverridePatterns query",
      "description": "As a platform admin, I see override analytics.",
      "acceptanceCriteria": [
        "Create models/coachOverrideAnalytics.ts",
        "Add getCoachOverridePatterns query with args: coachId (optional for per-coach), organizationId (optional for per-org)",
        "Query coachParentSummaries where overrideType is not null",
        "Aggregate counts by overrideType",
        "Calculate patterns: avgConfidenceWhenRejected, commonFeedbackReasons, overrideRateByCategory",
        "Returns: v.object({ totalOverrides: v.number(), byType: v.any(), patterns: v.any() })",
        "Typecheck passes"
      ],
      "priority": 19,
      "passes": false,
      "notes": "Analytics for AI improvement. See patterns: 'This coach rejects injury summaries 40% of the time even at 80% confidence - AI might be over-confident on injuries for this coach.'"
    },
    {
      "id": "US-020",
      "title": "Implement adaptive confidence thresholds",
      "description": "As a coach, my threshold adjusts based on my patterns.",
      "acceptanceCriteria": [
        "Add calculatePersonalizedThreshold function to lib/autoApprovalDecision.ts",
        "Inputs: coach override history, default threshold (0.7)",
        "If coach frequently approves low confidence summaries (>50% approval rate for 60-70% confidence): lower threshold by 5%",
        "If coach frequently rejects high confidence summaries (>20% rejection rate for 80%+ confidence): raise threshold by 5%",
        "Cap adjustments: 0.6 min, 0.85 max (don't go too aggressive or conservative)",
        "Store personalizedThreshold in coachTrustLevels (separate from user-set confidenceThreshold)",
        "Use personalizedThreshold in auto-approval decision if exists",
        "Create adjustPersonalizedThresholds scheduled function (runs weekly)",
        "Typecheck passes"
      ],
      "priority": 20,
      "passes": false,
      "notes": "AI learns per coach. Conservative coach gets higher threshold, trusting coach gets lower. Weekly batch job analyzes patterns and adjusts. Industry: Netflix recommendation tuning, Spotify playlist personalization."
    }
  ]
}
