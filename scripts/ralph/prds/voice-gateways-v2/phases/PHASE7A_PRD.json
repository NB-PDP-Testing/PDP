{
  "phaseNumber": "7A",
  "phaseName": "Wire In-App Notes to v2 Artifact Pipeline",
  "duration": "2-3 days",
  "storyCount": 2,
  "contextFiles": [
    "scripts/ralph/prds/voice-gateways-v2/context/V2_MIGRATION_CONTEXT.md",
    "scripts/ralph/prds/voice-gateways-v2/context/MAIN_CONTEXT.md",
    "docs/architecture/voice-notes-pipeline-v2.md"
  ],
  "previousPhases": [
    "Phase 1",
    "Phase 2",
    "Phase 2.5",
    "Phase 3",
    "Phase 4",
    "Phase 5",
    "Phase 6"
  ],
  "currentPhase": "Phase 7A - Wire In-App Notes to v2 Artifact Pipeline",
  "goal": "ALL voice notes (in-app typed, in-app recorded) create v2 artifacts when the v2 feature flag is enabled. Eliminate duplicate v1+v2 processing. v1 buildInsights becomes fallback only.",

  "referencePatterns": {
    "whatsappAudioV2": "packages/backend/convex/actions/whatsapp.ts lines 753-814 — STUDY THIS: shows the complete pattern for creating v2 artifact, v1 note, and linking them. In-app notes should follow the same pattern.",
    "whatsappTextV2": "packages/backend/convex/actions/whatsapp.ts lines 867-923 — STUDY THIS: shows text note v2 pattern (artifact creation, note creation, linking). Note: WhatsApp text does NOT create a transcript or schedule extractClaims — Phase 7A fixes this for in-app notes.",
    "transcribeAudioV2Bridge": "packages/backend/convex/actions/voiceNotes.ts lines 229-263 — STUDY THIS: shows how transcribeAudio already detects v2 artifacts and schedules extractClaims. Recorded notes leverage this automatically."
  },

  "verifiedFunctionSignatures": {
    "createArtifact": {
      "location": "packages/backend/convex/models/voiceNoteArtifacts.ts:62-97",
      "type": "internalMutation",
      "args": "{ artifactId: v.string(), sourceChannel: sourceChannelValidator, senderUserId: v.string(), orgContextCandidates: v.array(v.object({ organizationId: v.string(), confidence: v.number() })), rawMediaStorageId: v.optional(v.id('_storage')), metadata: v.optional(v.object({ mimeType: v.optional(v.string()), fileSize: v.optional(v.number()), whatsappMessageId: v.optional(v.string()) })) }",
      "returns": "v.id('voiceNoteArtifacts')",
      "notes": "Status is hardcoded to 'received'. createdAt/updatedAt set internally. Does NOT accept voiceNoteId — use linkToVoiceNote separately."
    },
    "linkToVoiceNote": {
      "location": "packages/backend/convex/models/voiceNoteArtifacts.ts:103-126",
      "type": "internalMutation",
      "args": "{ artifactId: v.string(), voiceNoteId: v.id('voiceNotes') }",
      "returns": "v.null()",
      "notes": "artifactId is the UUID STRING (not Convex _id). Finds artifact by by_artifactId index, patches with voiceNoteId."
    },
    "updateArtifactStatus": {
      "location": "packages/backend/convex/models/voiceNoteArtifacts.ts:132+",
      "type": "internalMutation",
      "args": "{ artifactId: v.string(), status: artifactStatusValidator }",
      "returns": "v.null()",
      "notes": "artifactId is the UUID STRING. Use after creating transcript for typed notes to set status='transcribed'."
    },
    "createTranscript": {
      "location": "packages/backend/convex/models/voiceNoteTranscripts.ts:25-45",
      "type": "internalMutation",
      "args": "{ artifactId: v.id('voiceNoteArtifacts'), fullText: v.string(), segments: v.array(segmentValidator), modelUsed: v.string(), language: v.string(), duration: v.number() }",
      "returns": "v.id('voiceNoteTranscripts')",
      "notes": "artifactId is the Convex _id (returned by createArtifact). segmentValidator expects { text, startTime, endTime, confidence }."
    },
    "shouldUseV2Pipeline": {
      "location": "packages/backend/convex/lib/featureFlags.ts:35-55",
      "type": "internalQuery",
      "args": "{ organizationId: v.string(), userId: v.string() }",
      "returns": "v.boolean()"
    },
    "extractClaims": {
      "location": "packages/backend/convex/actions/claimsExtraction.ts:427+",
      "type": "internalAction",
      "args": "{ artifactId: v.id('voiceNoteArtifacts') }",
      "returns": "v.null()",
      "notes": "artifactId is the Convex _id (returned by createArtifact)."
    },
    "getArtifactsByVoiceNote": {
      "location": "packages/backend/convex/models/voiceNoteArtifacts.ts",
      "type": "internalQuery",
      "args": "{ voiceNoteId: v.id('voiceNotes') }",
      "returns": "array of artifacts"
    },
    "buildInsights": {
      "location": "packages/backend/convex/actions/voiceNotes.ts:311+",
      "type": "internalAction",
      "args": "{ noteId: v.id('voiceNotes') }",
      "returns": "v.null()"
    },
    "createTypedNote": {
      "location": "packages/backend/convex/models/voiceNotes.ts:554-584",
      "type": "mutation (public)",
      "args": "{ orgId: v.string(), coachId: v.string(), noteText: v.string(), noteType: noteTypeValidator, source: v.optional(v.union(v.literal('app_typed'), v.literal('whatsapp_text'))) }",
      "returns": "v.id('voiceNotes')",
      "notes": "Inserts voiceNotes at line 566. Schedules buildInsights at lines 579-581."
    },
    "createRecordedNote": {
      "location": "packages/backend/convex/models/voiceNotes.ts:591-621",
      "type": "mutation (public)",
      "args": "{ orgId: v.string(), coachId: v.string(), audioStorageId: v.id('_storage'), noteType: noteTypeValidator, source: v.optional(v.union(v.literal('app_recorded'), v.literal('whatsapp_audio'))) }",
      "returns": "v.id('voiceNotes')",
      "notes": "Inserts voiceNotes at line 603. Schedules transcribeAudio at lines 616-620."
    }
  },

  "stories": [
    {
      "id": "US-VN-022",
      "phase": "7A",
      "title": "Wire In-App Note Creation to v2 Artifact Pipeline",
      "description": "Modify createTypedNote and createRecordedNote mutations to create voiceNoteArtifacts when the v2 pipeline is enabled. This makes in-app notes follow the same v2 processing path as WhatsApp notes. For recorded notes, transcribeAudio already detects artifacts and schedules extractClaims. For typed notes, we must also create a transcript and schedule extractClaims directly.",
      "acceptanceCriteria": [
        "=== REFERENCE PATTERN ===",
        "BEFORE coding, study the WhatsApp v2 audio pattern in actions/whatsapp.ts lines 753-814.",
        "That pattern is: (1) check v2 flag, (2) create artifact, (3) create v1 note, (4) linkToVoiceNote.",
        "For in-app notes the ORDER is different because the voice note is created FIRST (line 566/603), THEN the artifact.",
        "So our in-app pattern is: (1) create v1 note [existing], (2) check v2 flag, (3) create artifact, (4) linkToVoiceNote, (5) create transcript [typed only], (6) update status [typed only], (7) schedule extractClaims [typed only].",
        "",
        "=== IMPORTANT: internal IS ALREADY IMPORTED ===",
        "Line 2 of models/voiceNotes.ts already has: import { components, internal } from '../_generated/api';",
        "Do NOT add a duplicate import. Just use `internal.models.voiceNoteArtifacts.createArtifact` etc. directly.",
        "",
        "=== MODIFY: models/voiceNotes.ts — createTypedNote (line 554-584) ===",
        "After the voiceNotes insert at line 566 and BEFORE the buildInsights scheduling at line 579,",
        "add the v2 artifact creation block. All code below goes between lines 566 and 579:",
        "",
        "STEP 1: Check v2 feature flag",
        "  const useV2 = await ctx.runQuery(internal.lib.featureFlags.shouldUseV2Pipeline, {",
        "    organizationId: args.orgId,",
        "    userId: args.coachId,",
        "  });",
        "",
        "STEP 2: If v2 enabled, create artifact + transcript + schedule extractClaims",
        "  if (useV2) {",
        "    const artifactIdStr = crypto.randomUUID();",
        "",
        "    // 2a. Create artifact (returns Convex _id)",
        "    const artifactConvexId = await ctx.runMutation(",
        "      internal.models.voiceNoteArtifacts.createArtifact,",
        "      {",
        "        artifactId: artifactIdStr,",
        "        sourceChannel: 'app_typed' as const,",
        "        senderUserId: args.coachId,",
        "        orgContextCandidates: [",
        "          { organizationId: args.orgId, confidence: 1.0 },",
        "        ],",
        "      }",
        "    );",
        "",
        "    // 2b. Link artifact to the voice note we just created",
        "    await ctx.runMutation(",
        "      internal.models.voiceNoteArtifacts.linkToVoiceNote,",
        "      { artifactId: artifactIdStr, voiceNoteId: noteId }",
        "    );",
        "",
        "    // 2c. Create transcript from the typed text",
        "    await ctx.runMutation(",
        "      internal.models.voiceNoteTranscripts.createTranscript,",
        "      {",
        "        artifactId: artifactConvexId,",
        "        fullText: args.noteText,",
        "        segments: [{ text: args.noteText, startTime: 0, endTime: 0, confidence: 1.0 }],",
        "        modelUsed: 'user_typed',",
        "        language: 'en',",
        "        duration: 0,",
        "      }",
        "    );",
        "",
        "    // 2d. Update artifact status to 'transcribed' (typed text = instant transcript)",
        "    await ctx.runMutation(",
        "      internal.models.voiceNoteArtifacts.updateArtifactStatus,",
        "      { artifactId: artifactIdStr, status: 'transcribed' }",
        "    );",
        "",
        "    // 2e. Schedule extractClaims (v2 AI pipeline)",
        "    await ctx.scheduler.runAfter(",
        "      0,",
        "      internal.actions.claimsExtraction.extractClaims,",
        "      { artifactId: artifactConvexId }",
        "    );",
        "  }",
        "",
        "STEP 3: The EXISTING buildInsights scheduling (lines 579-581) stays as-is for now.",
        "  US-VN-023 will gate it with the useV2 variable. Do NOT modify it in this story.",
        "",
        "CRITICAL NOTES:",
        "  - createArtifact returns Convex _id (use for createTranscript and extractClaims)",
        "  - linkToVoiceNote takes the UUID string (artifactIdStr), NOT the Convex _id",
        "  - crypto.randomUUID() is available globally in Convex runtime (no import needed)",
        "  - All ctx.runMutation calls are valid inside a mutation handler",
        "  - Add ALL new code in a SINGLE edit to avoid linter removing unused references",
        "",
        "=== MODIFY: models/voiceNotes.ts — createRecordedNote (line 591-621) ===",
        "After the voiceNotes insert at line 603 and BEFORE the transcribeAudio scheduling at line 616,",
        "add the v2 artifact creation block:",
        "",
        "STEP 1: Check v2 feature flag",
        "  const useV2 = await ctx.runQuery(internal.lib.featureFlags.shouldUseV2Pipeline, {",
        "    organizationId: args.orgId,",
        "    userId: args.coachId,",
        "  });",
        "",
        "STEP 2: If v2 enabled, create artifact and link it",
        "  if (useV2) {",
        "    const artifactIdStr = crypto.randomUUID();",
        "",
        "    // 2a. Create artifact (status defaults to 'received' — transcript will come later via transcribeAudio)",
        "    await ctx.runMutation(",
        "      internal.models.voiceNoteArtifacts.createArtifact,",
        "      {",
        "        artifactId: artifactIdStr,",
        "        sourceChannel: 'app_recorded' as const,",
        "        senderUserId: args.coachId,",
        "        orgContextCandidates: [",
        "          { organizationId: args.orgId, confidence: 1.0 },",
        "        ],",
        "        rawMediaStorageId: args.audioStorageId,",
        "      }",
        "    );",
        "",
        "    // 2b. Link artifact to the voice note we just created",
        "    await ctx.runMutation(",
        "      internal.models.voiceNoteArtifacts.linkToVoiceNote,",
        "      { artifactId: artifactIdStr, voiceNoteId: noteId }",
        "    );",
        "  }",
        "",
        "STEP 3: The EXISTING transcribeAudio scheduling (lines 616-620) stays as-is.",
        "  transcribeAudio already detects artifacts via getArtifactsByVoiceNote (line 229) and",
        "  schedules extractClaims if artifact exists (line 259-263). No change needed.",
        "",
        "  NOTE: Do NOT create a transcript here — transcribeAudio handles that for recorded notes.",
        "  NOTE: Do NOT schedule extractClaims here — transcribeAudio handles that too.",
        "",
        "=== VERIFY ===",
        "Type check: npm run check-types",
        "Convex codegen: npx -w packages/backend convex codegen",
        "v2 OFF: createTypedNote creates voiceNotes only (no artifact) — same as before",
        "v2 OFF: createRecordedNote creates voiceNotes only (no artifact) — same as before",
        "v2 ON: createTypedNote creates voiceNotes + artifact + transcript + schedules extractClaims",
        "v2 ON: createRecordedNote creates voiceNotes + artifact (transcript + claims via transcribeAudio)"
      ],
      "priority": 22,
      "passes": false,
      "effort": "1.5 days",
      "effortBreakdown": {
        "createTypedNote_v2": "3h (feature flag, artifact, link, transcript, status update, extractClaims)",
        "createRecordedNote_v2": "2h (feature flag, artifact, link)",
        "testing_v2_on": "2h (verify full v2 pipeline for typed + recorded notes)",
        "testing_v2_off": "1h (verify v1 fallback still works identically)",
        "manual_convex_dashboard": "0.5h (verify artifacts, transcripts, claims in Convex dashboard)"
      },
      "dependencies": ["US-VN-021"],
      "files": {
        "create": [],
        "modify": [
          "packages/backend/convex/models/voiceNotes.ts (add v2 artifact creation to createTypedNote and createRecordedNote)"
        ]
      },
      "testingRequirements": {
        "unitTests": false,
        "integrationTests": false,
        "manualTesting": true,
        "uatTestCases": [
          "v2 ON + typed note → Convex dashboard shows: voiceNoteArtifact (sourceChannel=app_typed, status=transcribed) + voiceNoteTranscript + voiceNoteClaims",
          "v2 ON + recorded note → Convex dashboard shows: voiceNoteArtifact (sourceChannel=app_recorded, status=received) → after transcription: transcript + claims",
          "v2 OFF + typed note → NO artifact in voiceNoteArtifacts table, buildInsights runs normally",
          "v2 OFF + recorded note → NO artifact, transcribeAudio + buildInsights run normally",
          "v2 ON + typed note → artifact.voiceNoteId is populated (linkToVoiceNote worked)",
          "v2 ON + recorded note → artifact.voiceNoteId is populated"
        ]
      }
    },
    {
      "id": "US-VN-023",
      "phase": "7A",
      "title": "Eliminate Duplicate v1+v2 Processing",
      "description": "When v2 pipeline is active and an artifact exists for a voice note, skip the v1 buildInsights action. This prevents duplicate insights from both pipelines running simultaneously. Also audit v2 backend files for Convex .filter() anti-pattern.",
      "acceptanceCriteria": [
        "=== MODIFY: actions/voiceNotes.ts — buildInsights (line 311+) ===",
        "At the START of the buildInsights handler (after getting the note from db),",
        "add v2 artifact-exists check:",
        "",
        "  // v2 skip check: if artifact exists, v2 pipeline handles this note",
        "  const artifacts = await ctx.runQuery(",
        "    internal.models.voiceNoteArtifacts.getArtifactsByVoiceNote,",
        "    { voiceNoteId: args.noteId }",
        "  );",
        "  if (artifacts.length > 0) {",
        "    console.log('[buildInsights] Skipping v1 extraction — v2 artifact exists for note:', args.noteId);",
        "    return null;",
        "  }",
        "",
        "This check is SAFE because:",
        "  - US-VN-022 creates artifacts BEFORE buildInsights is scheduled (same mutation context)",
        "  - For recorded notes, transcribeAudio creates transcript + schedules extractClaims BEFORE scheduling buildInsights",
        "  - WhatsApp creates artifacts before triggering the note creation mutation",
        "",
        "IMPORT NOTE: internal is already imported at the top of actions/voiceNotes.ts.",
        "  Verify: internal.models.voiceNoteArtifacts.getArtifactsByVoiceNote should be accessible.",
        "  If not, check the import and add it in the same edit as the usage.",
        "",
        "=== MODIFY: actions/voiceNotes.ts — transcribeAudio ===",
        "NO CHANGE NEEDED. The existing code at lines 287-293 schedules buildInsights,",
        "but the skip check we just added to buildInsights handles this case.",
        "If an artifact exists, buildInsights returns early. This is the simplest approach.",
        "",
        "=== AUDIT: .filter() anti-pattern in v2 files ===",
        "Search these files for Convex query .filter() usage (NOT JavaScript array .filter()):",
        "  - packages/backend/convex/actions/entityResolution.ts",
        "  - packages/backend/convex/actions/draftGeneration.ts",
        "  - packages/backend/convex/models/voiceNoteEntityResolutions.ts",
        "  - packages/backend/convex/models/insightDrafts.ts",
        "",
        "HOW TO TELL THE DIFFERENCE:",
        "  ctx.db.query('table').filter(...)     → BAD (Convex query filter, ban it)",
        "  ctx.db.query('table').withIndex(...)   → GOOD",
        "  someArray.filter(...)                  → FINE (JavaScript array filter)",
        "  results.filter(...)                    → FINE (post-collect JS filter)",
        "",
        "If Convex .filter() found, replace with .withIndex() + add new index to schema.ts if needed.",
        "If only JS array .filter() found (after .collect()), leave it alone.",
        "",
        "=== VERIFY ===",
        "Type check: npm run check-types",
        "Convex codegen: npx -w packages/backend convex codegen",
        "v2 ON + artifact exists: buildInsights logs skip message and returns null",
        "v2 OFF + no artifact: buildInsights runs full v1 extraction normally",
        "grep -r '.filter(' in v2 backend files — only JS array .filter() remains"
      ],
      "priority": 23,
      "passes": false,
      "effort": "1 day",
      "effortBreakdown": {
        "buildInsights_skip": "1.5h (add artifact check at top of handler)",
        "filter_audit": "2h (scan 4 files, fix any Convex .filter(), add indexes if needed)",
        "testing_v2_on": "1.5h (verify skip for typed + recorded + WhatsApp notes)",
        "testing_v2_off": "1h (verify v1 fallback runs normally)",
        "manual_convex_logs": "1h (check Convex dashboard function logs for skip messages)"
      },
      "dependencies": ["US-VN-022"],
      "files": {
        "create": [],
        "modify": [
          "packages/backend/convex/actions/voiceNotes.ts (add v2 skip check to buildInsights)",
          "packages/backend/convex/actions/entityResolution.ts (fix .filter() if found)",
          "packages/backend/convex/actions/draftGeneration.ts (fix .filter() if found)",
          "packages/backend/convex/models/voiceNoteEntityResolutions.ts (fix .filter() if found)",
          "packages/backend/convex/models/insightDrafts.ts (fix .filter() if found)",
          "packages/backend/convex/schema.ts (add indexes if needed for .filter() replacements)"
        ]
      },
      "testingRequirements": {
        "unitTests": false,
        "integrationTests": false,
        "manualTesting": true,
        "uatTestCases": [
          "v2 ON: create typed note → Convex logs show '[buildInsights] Skipping v1 extraction'",
          "v2 ON: create recorded note → after transcription, Convex logs show skip message",
          "v2 OFF: create typed note → buildInsights runs normally, insights appear in dashboard",
          "v2 OFF: create recorded note → full v1 pipeline works",
          "grep for .filter() in v2 backend files → only JS array .filter() remains"
        ]
      }
    }
  ],

  "mandatoryPatterns": [
    "ALWAYS use .withIndex() — NEVER use Convex .filter()",
    "ALWAYS add imports AND usage in the SAME edit — linter removes unused imports between edits",
    "ALWAYS feature-flag v2 changes behind shouldUseV2Pipeline — v1 must work when v2 is disabled",
    "createArtifact does NOT accept voiceNoteId — use linkToVoiceNote separately",
    "createArtifact returns Convex _id — use for createTranscript and extractClaims args",
    "linkToVoiceNote takes UUID string (not Convex _id) — use the artifactIdStr variable",
    "crypto.randomUUID() is available globally in Convex — no import needed",
    "internal is already imported at line 2 of models/voiceNotes.ts — do not add duplicate"
  ],

  "ralphInstructions": {
    "executionMode": "sequential",
    "storyOrder": ["US-VN-022", "US-VN-023"],
    "beforeStarting": [
      "Read V2_MIGRATION_CONTEXT.md thoroughly — it explains the full v1 vs v2 architecture",
      "Study the WhatsApp v2 pattern in actions/whatsapp.ts lines 753-814 — replicate this for in-app notes",
      "Read models/voiceNoteArtifacts.ts lines 62-126 — understand createArtifact and linkToVoiceNote signatures"
    ],
    "testingStrategy": "Manual testing — create notes via the app with v2 flag ON and OFF, verify in Convex dashboard",
    "qualityCriteria": "npm run check-types passes, npx -w packages/backend convex codegen succeeds"
  },

  "successCriteria": {
    "allSourcesCreateArtifacts": "In-app typed and recorded notes create v2 artifacts when v2 flag is enabled",
    "typedNotesGetTranscripts": "Typed notes create voiceNoteTranscript with fullText = noteText and modelUsed = 'user_typed'",
    "typedNotesScheduleExtractClaims": "Typed notes schedule extractClaims immediately (since transcript is instant)",
    "recordedNotesLeverageTranscribeAudio": "Recorded notes rely on transcribeAudio to detect artifact and schedule extractClaims",
    "artifactsLinkedToNotes": "All artifacts have voiceNoteId populated via linkToVoiceNote",
    "noDuplicateProcessing": "buildInsights returns early when v2 artifact exists — only v2 extractClaims runs",
    "v1FallbackWorks": "With v2 OFF, everything works exactly as before — no artifacts, buildInsights runs normally"
  }
}
