# UAT Test: US-012 - Add prompt caching to generateParentSummary action

> Auto-generated: 2026-01-24 23:50
> Status: ‚è≥ Pending Execution

## Story
As a platform, I reduce AI costs by 90% through Anthropic prompt caching.

## Acceptance Criteria Checklist

- [ ] Edit packages/backend/convex/actions/generateParentSummary.ts
- [ ] Add anthropic-beta header: 'anthropic-beta': 'prompt-caching-2024-07-31'
- [ ] Structure messages array to cache system prompt and player/sport context
- [ ] Only insight content varies (no cache on that)
- [ ] Extract cache statistics from API response: usage.cache_creation_input_tokens, usage.cache_read_input_tokens
- [ ] Update cost calculation: (input_tokens - cached_tokens) * 0.000005 + cached_tokens * 0.0000005 + output_tokens * 0.000015
- [ ] Return cache stats in action response for logging
- [ ] Typecheck passes: npm run check-types

## Test Scenarios

### Happy Path
1. Navigate to the feature
2. Perform the primary action described in the story
3. Verify all acceptance criteria are met
4. **Expected:** Feature works as described

### Edge Cases
1. Test with empty/null values
2. Test with boundary values
3. Test rapid repeated actions
4. **Expected:** Graceful handling, no errors

### Error Handling
1. Test with invalid inputs
2. Test without proper permissions
3. Test with network issues (if applicable)
4. **Expected:** Clear error messages, no crashes

## Visual Verification
- [ ] UI matches design expectations
- [ ] Responsive on mobile (if applicable)
- [ ] Loading states are appropriate
- [ ] Error states are user-friendly

## Notes
_Add testing observations here_

---
*Generated by Test Runner Agent*
